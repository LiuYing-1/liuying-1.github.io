<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="googlece17f0a456a89a36.html"> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Extracts from BYOL | Y. Liu </title> <meta name="author" content="Y. Liu"> <meta name="description" content="Review of the paper BYOL and to extract the main points"> <meta name="keywords" content="ku, ucph, copenhagen, diku, portfolio-website, liuying, dk, yingliu, ying liu, liu ying"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link defer href="/assets/css/bootstrap-toc.min.css?6f5af0bb9aab25d79b2448143cbeaa88" rel="stylesheet"> <link rel="shortcut icon" href="/assets/img/favicon.png?157bbd74cef60250fd5a67a2e078966e"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://liuying-1.github.io/blog/2024/byol/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Y.</span> Liu </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">Ctrl K <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="row"> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> <div class="col-sm-9"> <div class="post"> <header class="post-header"> <h1 class="post-title">Extracts from BYOL</h1> <p class="post-meta"> Created in February 11, 2024 </p> <p class="post-tags"> <a href="/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/tag/ssl"> <i class="fa-solid fa-hashtag fa-sm"></i> ssl</a>   ·   <a href="/blog/category/study"> <i class="fa-solid fa-tag fa-sm"></i> study</a>   <a href="/blog/category/ucph"> <i class="fa-solid fa-tag fa-sm"></i> ucph</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>BYOL is the abbr. of <u>Bootstrap Your Own Latent: A New Approach to Self-Supervised Learning</u>.</p> <h3 id="cookbook-for-byol">Cookbook for BYOL</h3> <p>First of all, BYOL method probably the first one removes the clustering step, introduces a predictor and projector network, fefines the continuous targets as the output of a momentum network, renormalize each sample representation by its \(l_2\)-norm and leverage positive pairs. The predictor acts as a whitening operator preventing collapse, and momentum network can be applied only to the projector.</p> <p>It first introduced self-distillation as a means to avoid collapse. It usees two networks along with a predictor to map the outputs of one network to the other. The network predicting the output is called the online or student network while the network producing the target is called the target or teacher network. Each network receives a different view of the same image formed by image transformations including random resizing, cropping, color jittering, and brightness alterations. The student network is updated throughout training using gradient descent. The teacher network is updated with an exponential moving average (EMA) updates of the weights of the online network. The slow updates induced by exponential moving average creates an asymmetry that is crucial to BYOL’s success.</p> <h3 id="original-paper">Original Paper</h3> <p>Please check the original paper here <a href="https://arxiv.org/abs/2006.07733" rel="external nofollow noopener" target="_blank">BYOL</a>.</p> <h4 id="abstract">Abstract</h4> <ul> <li> <strong>BYOL</strong>, a <strong>new</strong> apporach to <strong>self-supervised learning</strong>.</li> <li>BYOL relies on two neural networks, referred to as the <strong>online</strong> network and the <strong>target</strong> network, that <strong>interact</strong> and <strong>learn from each other</strong>.</li> <li>From <strong>an augmented view of an image</strong>, we train the <strong>online network to predict the target network representation of the same image under a different augmented view</strong>.</li> <li>At the same time, we <strong>update the target network with a slow-moving average of the online network</strong>.</li> <li>(Back then), while state-of-the-art methods <strong>rely on negative pairs</strong>, BYOL achieves a new state of the art <strong>without them</strong>.</li> </ul> <hr> <p>Online first updates, updates of target come from online by EMA.</p> <p>Without negative pairs can be competative as well.</p> <p>Train the online to predict the target network representation.</p> <hr> <h4 id="introduction">Introduction</h4> <ul> <li>(Back then,) state-of-the-art <strong>contrastive methods</strong> are trained by <strong>reducing the distance between representations of different augmented views of the same image (‘positive pairs’)</strong>, and <strong>increasing the distance between representations of augmented views from different images (‘negative pairs’)</strong>.</li> <li>These methods need <strong>careful treatment of negative pairs</strong> by either <strong>relying on large batch sizes</strong>, <strong>memory banks</strong> or <strong>customized mining strategies</strong> to retrieve the negative pairs.</li> <li>In addition, their performance <strong>critically</strong> depends on the <strong>choice of image augmentations</strong>.</li> </ul> <hr> <p>BYOL can overcome the previous shortages from the previous methods, which are: <strong>no need negative pairs</strong>, <strong>careful treatment of negative pairs</strong>, <strong>choice of hyper-parameters</strong>, and <strong>choice of augmentations</strong>.</p> <hr> <ul> <li>BYOL achieves higher performance than state-of-the-art contrastive methods <strong>without using negative pairs</strong>.</li> <li>It <strong>iteratively</strong> <strong>bootstraps the outputs of a network to serve as targets for an enhanced representation</strong>.</li> <li>BYOL is <strong>more robust</strong> to the <strong>choice of image augmentations</strong> than contrastive methods; we suspect that <strong>not relying on negative pairs</strong> is one of the leading reasons for its <strong>improved robustness</strong>.</li> <li>We propose to <strong>directly bootstrap the representations</strong>. ==&gt; Different from previous methods.</li> <li>In particular, <strong>BYOL uses two neural networks, referred to as online and target networks, that interatct and learn from each other.</strong> </li> <li>Starting from <strong>an augmented view of an image</strong>, BYOL <strong>trains its online network</strong> to <strong>predict the target network’s representation</strong> of <strong>another augmented view</strong> of the <strong>same image</strong>.</li> <li>While this objective <strong>admits collapsed solutions</strong>, e.g., <strong>outputting the same vector for all images</strong>, we empirically show that <strong>BYOL does not converage to such solutions</strong>.</li> <li>We hypothesize that the <strong>combination</strong> of (i) the <strong>addition of a predictor to the online network</strong> and (ii) the <strong>use of a slow-moving average of the online parameters as the target network</strong> encourages <strong>encoding more and more information within the online projection</strong> and <strong>avoids collapsed solutions</strong>.</li> </ul> <hr> <ul> <li>BYOL achieves state-of-the-art results under the <strong>linear evaluation protocol on ImageNet without using negative pairs</strong>.</li> <li>Our learned representation outperforms the state of the art on semi-supervised and transfer benchmarks.</li> <li>BYOL is <strong>more resilient</strong> to <strong>changes in the batch size</strong> and <strong>in the set of image augmentations</strong> compared to its contrastive counterparts.</li> <li>In particular, BYOL sufferes a much smaller performance drop than SimCLR, a strong contrastive basline, when only using random crops as image augmentations.</li> </ul> <h4 id="related-work">Related work</h4> <ul> <li>Most <strong>unsupervised methods for representation learning</strong> can be categorized as either <strong>generative</strong> or <strong>discriminative</strong>.</li> <li> <strong>Generative approaches to representation learning</strong> build <strong>a distribution over data and latent embedding</strong> and <strong>use the learned embeddings as image representations</strong>.</li> <li>Many of these apporaches <strong>rely either on auto-encoding of images</strong> or on <strong>adversarial learning</strong>, jointly modelling data and representation.</li> <li>Generative methods typically operate <strong>directly in pixel space</strong>.</li> <li>This however is <strong>computationally expensive</strong>, and the <strong>high level of detail required for image generation</strong> may <strong>not be necessary</strong> for representation learning.</li> </ul> <hr> <p>The <strong>intro</strong> and <strong>drawbacks</strong> of generative methods.</p> <hr> <ul> <li>Among <strong>discriminative</strong> methods, <strong>contrastive methods</strong> currently achieves state-of-the-art performance in self-supervised learning.</li> <li> <strong>Contrastive methods often</strong> require comparing each example with many other examples to work well, <strong>prompting the question of whether using negative pairs is necessary</strong>.</li> </ul> <hr> <p><strong>Contrastive methods</strong> belongs to <strong>discriminative methods</strong>, and are best, while <strong>prompting the question of negative pairs</strong>.</p> <hr> <ul> <li> <strong>DeepCluster partially answers this question</strong>.</li> <li>While <strong>avoiding the use of negative pairs</strong>, this requires <strong>a costly clustering phase and specific precautions to avoid collapsing to trivial solutions</strong>.</li> </ul> <hr> <p>Might <strong>not necessary</strong> for the use of <strong>negative pairs</strong> if under suitable settings.</p> <hr> <ul> <li>Some self-supervised methods are <strong>not contrastive but rely on using auxiliary handcrafted prediction tasks</strong> to learn their representation.</li> <li>Yet, even with suitable architectures, these methods are being <strong>outperformed by contrastive methods</strong>.</li> </ul> <hr> <p>Some other methods might <strong>better</strong> than contrastive methods.</p> <hr> <ul> <li>Our approach <strong>has some similarities</strong> with <em>Predictions of Bootstrapped Latents</em> (PBL).</li> <li>PBL <strong>jointly trains the agent’s history representation</strong> and <strong>an encoding of future observations</strong>.</li> <li> <strong>Unlike PBL</strong>, <strong>BYOL uses a slow-moving average of its representation to provide its targets, and does not require a second network.</strong> </li> </ul> <hr> <p>BYOL stems from PBL but unlike PBL.</p> <hr> <ul> <li>The <strong>idea of using a slow-moving average target network to produce stable targets</strong> for the online network was inspired by deep RL.</li> <li> <p>Target networks stabilize the bootstrapping updates provided by the Bellman equation, <strong>making them appealing to stabilise the bootstrap mechanism in BYOL</strong>.</p> </li> <li>While <strong>most RL methods use fixed target networks</strong>, BYOL uses <strong>a weighted moving average of previous networks in order to provide smoother changes in the target representation</strong>.</li> </ul> <hr> <p>The origin of the moving weights.</p> <hr> <ul> <li>In the semi-supervised …. Among these methods, mean teacher also uses a slow-moving average network, called teacher, to produce targets for an online network, called student.</li> <li><strong>In contrast, BYOL introduces an additional predictor on top of the online network, which prevents collapse.</strong></li> </ul> <hr> <p>The use of predictor.</p> <hr> <ul> <li>Finally, in self-supervised learning, MoCo uses a slow-moving average network (momentum encoder) to maintain consistent representations of negative pairs drawn from a memory bank.</li> <li>Instead, <strong>BYOL uses a moving average network to produce prediction targets</strong> as a means of stabilizing the bootstrap step.</li> </ul> <h4 id="method">Method</h4> <ul> <li>Many such approaches <strong>cast the prediction problem directly in representation space</strong>: the <strong>representation of an augmented view of an image</strong> should be <strong>predictive of the representaion of another augmented view of the same image</strong>.</li> <li>However, <strong>predicting directly in represntation space</strong> can lead to <strong>collapsed representations</strong>.</li> <li>Contrastive methods circumvent this problem by reformulating the prediction problem into one of discrimination. … and the <strong>representations of augmented views of different images</strong>.</li> <li>In this work, we thus <strong>tasked ourselves to find out whether these negative examples are indispensable to prevent collapsing while preserving high performance.</strong> </li> </ul> <hr> <p>cross-view 能：图像的增强视图的表征能预测同一图的另一个增强的表征，但是代价是总能预测自己来导致 trivial solutions（坍塌）。所以我们的方法来验证能否保持高性能的同时，负样本的存在是否必须。</p> <hr> <ul> <li>To <strong>prevent collapse, a straightforward solution is to use a fixed randomly initialized network</strong> to poduce the <strong>targets</strong> for our predictions.</li> <li>While avoidng collapse, it <strong>empircally does not result in very good representations</strong>.</li> <li>It is interesting to note that the <strong>representation obtained using this procedure</strong> can already be <strong>much better than the initial fixed represntation</strong>.</li> <li>This experimental finding is the <strong>core motivation</strong> for BYOL: <strong>from a given representation, referred to as target, we can train a new, potentially enhanced representation, referred to as online, by predicting the target representation.</strong> </li> <li>We can expect to <strong>build a sequence of representations of increasing quality by iterating this procedure</strong>, <strong>using subsequent online networks as new target networks for further training.</strong> </li> <li>In practice, BYOL <strong>generalizes this bootstrapping procedure</strong> by <strong>iteratively refining its representation</strong>, but <strong>using a slowly moving exponential average of the online network</strong> as the target network <strong>instead of fixed checkpoints</strong>.</li> </ul> <hr> <p>经验觉得 fixed 不行，但是已经效果不错了，所以我们基于此设计了新的。从一个给定的表征（target）训练一个新的加强的表征（online）来预测 target 的表征。</p> <hr> <h5 id="description-of-byol">Description of BYOL</h5> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/7aUmfsC.png" alt="image-20230919201623320" class="img-fluid rounded z-depth-1" data-zoomable=""> </div> </div> <div class="caption"> Figure 1. BYOL's architectures </div> <ul> <li> <p>BYOL’s <strong>goal</strong> is to <strong>learn a representation</strong> \(y_\theta\) <strong>which can then be used for downstream tasks</strong>. ==&gt; <strong>representation</strong>.</p> </li> <li> <p>BYOL uses <strong>two neural networks</strong> to learn: the <strong>online</strong> and <strong>target networks</strong>.</p> </li> <li> <p>The <strong>online network is defined by a set of weights</strong> \(\theta\) and is comprised of <strong>three stages</strong>: an <em>encoder</em> \(f_\theta\), a projector \(g_\theta\) and a predictor \(q_\theta\)​.</p> </li> <li> <p>The <strong>target network has the same architecture as the online network</strong>, but <strong>uses a different set of weights</strong> \(\xi\).</p> </li> <li> <p>The <strong>target</strong> network provides the <strong>regression targets to train the online network</strong>, and its parameters \(\xi\) are an <strong>exponential moving average</strong> of the <strong>online</strong> parameters \(\theta\).</p> </li> <li> <p>Given a <strong>target decay rate</strong> \(\tau\in [0, 1]\)​, after each training step we perform the following update,</p> \[\xi \leftarrow \tau\xi + (1-\tau)\theta.\] </li> </ul> <hr> <p>Online: encoder \(encoder(f_\theta) + prejector(g_\theta) + predictor(q_\theta)\), target has the same architecture but with different parameters comes from the above mentioned equation based on online.</p> <hr> <ul> <li> <p>Given <strong>a set of images</strong> \(D\), an <strong>image</strong> \(x\sim D\) sampled uniformly from \(D\), and <strong>two distributions of image augmentations</strong> \(\mathcal{T}\) and \(\mathcal{T'}\), BYOL <strong>produces two augmented views</strong> \(v \triangleq t(x)\) and \(v'\triangleq t'(x)\) from \(x\) by <strong>applying respectively image augmentations</strong> \(t \sim \mathcal{T}\) and \(t' \sim \mathcal{T'}\). ==&gt; 从两个相同流程的增强策略上随机选两套，因为参数大概率不同，所以两套流程的参数不同，所以是两个不同的 view。</p> </li> <li> <p>From the <strong>first augmented view</strong> \(v\), the <strong>online network outputs</strong> a <em>representation</em> \(y_\theta \triangleq f_\theta(v)\) and a <strong>projection</strong> \(z_\theta\triangleq g_\theta(y)\).</p> </li> <li> <p>The <strong>target</strong> network outputs \(y'_\xi \triangleq f_\xi(v')\) and the <em>target projection</em> \(z'_\xi \triangleq g_\xi(y')\) from the <strong>second augmented view</strong> \(v'\)​.</p> </li> <li> <p>We then output a <strong>prediction</strong> \(q_\theta(z_\theta)\) of \(z'_\xi\) and \(l_2\)-normalize both \(q_\theta(z_\theta)\) and \(z'_\xi\)​ to</p> \[\overline{q_\theta}(z_\theta) \triangleq q_\theta(z_\theta)/\vert\vert q_\theta(z_\theta)\vert\vert_2\] <p>and</p> \[\overline{z'_\xi}/\vert\vert z'_\xi\vert\vert_2^2.\] </li> <li> <p>Note that this <strong>predictor is only applied to the online branch</strong>, making the <strong>architecture asymmetric between the online and target pipeline</strong>.</p> </li> <li> <p>Finally we dine the following mean squared error between the normalized predictions and target projections,</p> \[\mathcal{L}_{\theta, \xi} \triangleq \vert\vert{\overline{q_\theta}(z_\theta) - \overline{z'}_\xi}\vert\vert_2^2 = 2 - 2\cdot \frac{&lt;q_\theta(z_\theta), z'_\xi&gt;}{\vert\vert q_\theta(z_\theta)\vert\vert_2 \cdot \vert\vert z'_\xi\vert\vert_2}.\] </li> <li> <p>We <strong>symmetrize the loss above</strong> by separaetely feeding \(v'\) to the online network and \(v\) to the target network to compute the other one. ==&gt; 对称的换一下两个网络的 view，然后将两个相加形成最终的 loss。</p> </li> <li> <p>At <strong>each training step</strong>, we perform a stochastic optimization step to minimize</p> \[\mathcal{L}_{\theta, \xi}^{\text{BYOL}} = \mathcal{L}_{\theta, \xi} + \widetilde{\mathcal{L}}_{\theta, \xi}\] <p>with respect to \(\theta\) only, but not \(\xi\).</p> \[\theta \leftarrow \text{optimizer}(\theta, \nabla_\theta\mathcal{L}_{\theta, \xi}^{\text{BYOL}}, \eta),\\ \xi \leftarrow \tau\xi + (1-\tau)\theta\] <p>where optimizer is an optimzer and \(\eta\)​ is a learning rate.</p> </li> <li> <p>At the end of training, we <strong>only keep the encoder</strong> $f_{\theta}$.</p> </li> </ul> <h5 id="implementation-details">Implementation details</h5> <ul> <li>Image augmentations: <ul> <li>BYOL uses the same set of image augmentations as in SimCLR.</li> <li>First a <strong>random patch of the image</strong> is selected and <strong>resized</strong> to \(224\times 224\)​ with a random <strong>horizontal</strong> flip, followed by a <strong>color distrotion</strong>, consisting of a <strong>random sequence of brightness, contrast, saturation, hue adjustments, and an optional grayscale conversion</strong>. Finally, <strong>Gaussian blur</strong> and <strong>solarization</strong> are applied to the <strong>patches</strong>.</li> </ul> </li> <li> <strong>Architecture</strong> <ul> <li> <strong>ResNet</strong>-50 as our base parametric <strong>encoders</strong> \(f_\theta\) and \(f_\xi\)</li> <li>The <strong>representation</strong> $y$ <strong>corresopnds to the output of the final average pooling layer</strong>, which has a feature dimension of \(2048\).</li> <li>Contrary to SimCLR, the <strong>output</strong> of this MLP is <strong>not batch normalized</strong>. The <strong>predictor</strong> \(q_\theta\) uses the <strong>same</strong> <strong>architecture</strong> as \(g_\theta\)​.</li> </ul> </li> <li> <strong>Optimization</strong> <ul> <li> <strong>LARS</strong> <strong>optimizer</strong> with a <strong>cosine decay learning rate schedule</strong>, <strong>without restarts</strong>, over 1000 epochs, with a <strong>warm-up period of 10 epochs</strong>.</li> <li>the <strong>base learning rate</strong> to \(0.2\), scaled linearly with the batch size (Learning rate = \(0.2 \times \text{BatchSize}/256\))</li> <li>A global weight decay parameter of \(1.5\cdot 10^{-6}\) while excluding the biases and batch normalization parameters from both LARS adaptation and weight decay.</li> <li>A <strong>batch size of 4096</strong> </li> </ul> </li> </ul> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/line-segment-intersection/">Line Segment Intersection</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/graduation/">Graduation</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/swav/">Review of SwAV</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/simsiam/">Review of SimSiam</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/cookbook-1/">Cookbook Reading - 1</a> </li> </div> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Y. Liu. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="/assets/js/bootstrap-toc.min.js?c82ff4de8b0955d6ff14f5b05eed7eb6"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js" integrity="sha256-rjmgmaB99riUNcdlrDtcAiwtLIojSxNyUFdl+Qh+rB4=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-JC70RZ57BT"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-JC70RZ57BT");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"About",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"Blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-cv",title:"CV",description:"Here is a brief overview of my academic and professional background, and hope there is something interesting for you. The more comprehensive version can be accessed by clicking the PDF icon on right top corner of this page.",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"post-line-segment-intersection",title:"Line Segment Intersection",description:"Self-learning note for CG - Line Segment Intersection.",section:"Posts",handler:()=>{window.location.href="/blog/2024/line-segment-intersection/"}},{id:"post-graduation",title:"Graduation",description:"Congratulations to my graduation from the DIKU, University of Copenhagen.",section:"Posts",handler:()=>{window.location.href="/blog/2024/graduation/"}},{id:"post-review-of-swav",title:"Review of SwAV",description:"This is the learning of the paper SwAV.",section:"Posts",handler:()=>{window.location.href="/assets/pdf/swav.pdf"}},{id:"post-review-of-simsiam",title:"Review of SimSiam",description:"This is the learning of the paper SimSiam.",section:"Posts",handler:()=>{window.location.href="/assets/pdf/SimSIAM.pdf"}},{id:"post-extracts-from-byol",title:"Extracts from BYOL",description:"Review of the paper BYOL and to extract the main points",section:"Posts",handler:()=>{window.location.href="/blog/2024/byol/"}},{id:"post-cookbook-reading-1",title:"Cookbook Reading - 1",description:"This is the first part of this book.",section:"Posts",handler:()=>{window.location.href="/blog/2024/cookbook-1/"}},{id:"post-advanced-image-registration",title:"Advanced Image Registration",description:"Self-learning note for advanced image registration.",section:"Posts",handler:()=>{window.location.href="/blog/2023/advanced-image-registration/"}},{id:"post-image-registration-basics",title:"Image Registration Basics",description:"Learning note for medical image registration.",section:"Posts",handler:()=>{window.location.href="/blog/2023/image-registration-l1/"}},{id:"post-segmentation-basics",title:"Segmentation Basics",description:"Learning note for medical image segmentation.",section:"Posts",handler:()=>{window.location.href="/blog/2023/segmentation-basics/"}},{id:"post-inpainting",title:"Inpainting",description:"Learning note for inpainting.",section:"Posts",handler:()=>{window.location.href="/blog/2023/inpainting/"}},{id:"post-magnetic-resonance",title:"Magnetic Resonance",description:"Preview of the lecture for MRI.",section:"Posts",handler:()=>{window.location.href="/blog/2023/mia-mr/"}},{id:"post-x-ray-and-ct",title:"X-ray and CT",description:"This is the first lecture of the course Medical Image Analysis at UCPH.",section:"Posts",handler:()=>{window.location.href="/blog/2023/mia-l1/"}},{id:"post-dansk-gt-0307",title:"Dansk &gt; 0307",description:"This is the learning note for my first lesson at Ucplus.",section:"Posts",handler:()=>{window.location.href="/blog/2023/dansk-week-1/"}},{id:"post-dictation-gt-the-art-of-balancing-stones",title:"Dictation &gt; The Art of Balancing Stones",description:"This is a daily dictation 2 for English improvement.",section:"Posts",handler:()=>{window.location.href="/blog/2023/the-art-of-balancing-stones/"}},{id:"post-dictation-gt-the-egg",title:"Dictation &gt; The Egg",description:"This is a daily dictation 1 for English improvement.",section:"Posts",handler:()=>{window.location.href="/blog/2023/the-egg/"}},{id:"post-neural-network-ii-mlops",title:"Neural Network II | MLOps",description:"This is the lecture for Neural Network II and MLOps.",section:"Posts",handler:()=>{window.location.href="/blog/2023/ml-ops/"}},{id:"post-neural-network",title:"Neural Network",description:"Recap of Neural Network",section:"Posts",handler:()=>{window.location.href="/blog/2023/neural-network-recap/"}},{id:"post-easter-lunch",title:"Easter Lunch",description:"This is the first time to have lunch with my Danish family at Easter.",section:"Posts",handler:()=>{window.location.href="/blog/2023/easter-lunch/"}},{id:"post-segmentation",title:"Segmentation",description:"Image Segmentation, including Hough Transform",section:"Posts",handler:()=>{window.location.href="/blog/2023/segmentation/"}},{id:"post-features",title:"Features",description:"Image feature detection and matching with application.",section:"Posts",handler:()=>{window.location.href="/assets/pdf/features.pdf"}},{id:"post-transformation",title:"Transformation",description:"Affine, Rigid, Perspective linear transformations, etc.",section:"Posts",handler:()=>{window.location.href="/assets/pdf/geometry.pdf"}},{id:"post-deconvolution",title:"Deconvolution",description:"Image Restoration by Deconvolution",section:"Posts",handler:()=>{window.location.href="/blog/2023/deconvolution/"}},{id:"post-histogram",title:"Histogram",description:"Thresholding segmentation and histogram techniques.",section:"Posts",handler:()=>{window.location.href="/blog/2023/histogram/"}},{id:"post-fourier",title:"Fourier",description:"Complex numbers and Fourier transformation.",section:"Posts",handler:()=>{window.location.href="/blog/2023/fourier/"}},{id:"post-filtering",title:"Filtering",description:"Linear and non-linear filtering, derivative operators.",section:"Posts",handler:()=>{window.location.href="/blog/2023/filtering/"}},{id:"post-convolution",title:"Convolution",description:"Pixel-wise Operations, Intensity, Transformations, Image Formation, and the Convolution Integral.",section:"Posts",handler:()=>{window.location.href="/blog/2023/convolution/"}},{id:"post-app-and-term",title:"App and Term",description:"Introduction of the Signal and Image Processing course, including the basic concepts, terminology, and applications.",section:"Posts",handler:()=>{window.location.href="/blog/2023/intro/"}},{id:"post-aads-grade",title:"AADS Grade",description:"This is to record I got 12 on the course Advanced Algorithms and Data Structures.",section:"Posts",handler:()=>{window.location.href="/blog/2023/aads-grade/"}},{id:"post-polygon-triangulation",title:"Polygon Triangulation",description:"This is the learning note for Polygon Triangulation.",section:"Posts",handler:()=>{window.location.href="/assets/pdf/polygon.pdf"}},{id:"post-approximation",title:"Approximation",description:"This is the learning note for Approximation algorithm - 1.",section:"Posts",handler:()=>{window.location.href="/assets/pdf/approx1.pdf"}},{id:"post-exact-parameterized",title:"Exact-Parameterized",description:"This is the learning note for Exact-Parameterized algorithm.",section:"Posts",handler:()=>{window.location.href="/assets/pdf/EE.pdf"}},{id:"post-npc",title:"NPC",description:"This is the learning note for NPC.",section:"Posts",handler:()=>{window.location.href="/assets/pdf/NPC.pdf"}},{id:"post-van-emde-boas-tree",title:"van Emde Boas Tree",description:"This is the learning note for vEB.",section:"Posts",handler:()=>{window.location.href="/assets/pdf/van-Emde-Boas-Trees.pdf"}},{id:"post-sad-mood",title:"Sad Mood",description:"This blog is to record my current sad mood.",section:"Posts",handler:()=>{window.location.href="/blog/2023/sad-mood/"}},{id:"post-hashing",title:"Hashing",description:"This is the learning note for Hashing.",section:"Posts",handler:()=>{window.location.href="/assets/pdf/Hashing.pdf"}},{id:"post-randomized-algorithms",title:"Randomized Algorithms",description:"This is the learning note for the Randomized Algorithms.",section:"Posts",handler:()=>{window.location.href="/assets/pdf/RA.pdf"}},{id:"post-linear-programming",title:"Linear Programming",description:"This is the learning note for the Linear Programming.",section:"Posts",handler:()=>{window.location.href="/assets/pdf/Linear-programming.pdf"}},{id:"post-max-flow",title:"Max-flow",description:"This is the learning note for the Max-flow.",section:"Posts",handler:()=>{window.location.href="/assets/pdf/Max-flow.pdf"}},{id:"post-recovery-gt-crash",title:"Recovery &gt; Crash",description:"This is the special case of the recovery when the system crashes.",section:"Posts",handler:()=>{window.location.href="/blog/2023/recovery-crash/"}},{id:"post-recovery-gt-normal",title:"Recovery &gt; Normal",description:"This is the special part for recovery and normal.",section:"Posts",handler:()=>{window.location.href="/blog/2023/recovery-normal/"}},{id:"post-experiment-recovery",title:"Experiment | Recovery",description:"Here are the chapters of Experiments and Recovery.",section:"Posts",handler:()=>{window.location.href="/blog/2023/recover/"}},{id:"post-concourrency-2",title:"Concourrency 2",description:"This is the chapter relating to concurrency control - Part 2.",section:"Posts",handler:()=>{window.location.href="/blog/2023/concurrency-2/"}},{id:"post-concourrency-1",title:"Concourrency 1",description:"This is the chapter relating to concurrency control.",section:"Posts",handler:()=>{window.location.href="/blog/2022/concurrency/"}},{id:"post-godt-nyt\xe5r",title:"Godt Nyt\xe5r",description:"The blog is to record my first New Year&#39;s Eve in Denmark!",section:"Posts",handler:()=>{window.location.href="/blog/2022/godt-nytar/"}},{id:"post-incorrect-url",title:"Incorrect URL",description:"Last time, my neighbor, whose world ranking in CSGO is the Global Elite, received a Christmas gift by his nisse.",section:"Posts",handler:()=>{window.location.href="/blog/2022/incorrect-url/"}},{id:"post-rpc-performance",title:"RPC | Performance",description:"RPC and Permance are the two topics we will cover today.",section:"Posts",handler:()=>{window.location.href="/blog/2022/rpc/"}},{id:"post-abstractions",title:"Abstractions",description:"Basic concepts of computer systems.",section:"Posts",handler:()=>{window.location.href="/blog/2022/abstractions/"}},{id:"post-tivoli-firework",title:"Tivoli Firework",description:"To accompany Jianxiang Yu, we went to the second oldest theme park worldwide, Tivoli in Denmark yesterday.",section:"Posts",handler:()=>{window.location.href="/blog/2022/tivoli-firework/"}},{id:"post-royal-guardian",title:"Royal Guardian",description:"The shift of the royal guardian in Marmorkirken.",section:"Posts",handler:()=>{window.location.href="/blog/2022/royal-gardian/"}},{id:"post-swan-nearby",title:"Swan Nearby",description:"A record to keep this swan in my memory.",section:"Posts",handler:()=>{window.location.href="/blog/2022/swan-nearby/"}},{id:"post-chef-first-time",title:"Chef First Time",description:"This is my first time being the chef to cook for my danish family!",section:"Posts",handler:()=>{window.location.href="/blog/2022/chief-first-time/"}},{id:"post-travel-to-malm\xf6",title:"Travel to Malm\xf6",description:"This is the final version of the image preprocessing with the limitation that cannot automatically crop the image in the center. However, it can work properly in normal situations. Also, this blog is used to record my trip to Malm\xf6, Sweden with Xuanlang.",section:"Posts",handler:()=>{window.location.href="/blog/2022/travel-to-malmo/"}},{id:"post-dev-progress",title:"Dev Progress",description:"In this version, the development of my blog website is already passed half. \u8fd9\u91cc\u662f\u4e2d\u6587\u5b57\u4f53\u6d4b\u8bd5\u3002",section:"Posts",handler:()=>{window.location.href="/blog/2022/dev-progress/"}},{id:"post-take-metro",title:"Take Metro",description:"This blog is to record my route from DIKU back to my dorm at 00:53 am several days ago.",section:"Posts",handler:()=>{window.location.href="/blog/2022/take-metro/"}},{id:"post-start-my-blog",title:"Start My Blog",description:"Memorize the start of the implementation of my blog-web.",section:"Posts",handler:()=>{window.location.href="/blog/2022/start-my-blog/"}},{id:"news-i-have-defended-my-master-thesis-quot-exploration-of-self-supervised-learning-methods-for-longitudinal-image-analysis-quot-and-received-my-master-39-s-degree-meanwhile-i-have-been-offered-a-job-as-an-ai-engineer-in-a-company",title:"I have defended my master thesis **&quot;Exploration of Self-Supervised Learning Methods for Longitudinal Image Analysis&quot;** and received my Master&#39;s Degree. Meanwhile, I have been offered a job as an **AI Engineer** in a company. \ud83c\udf93\ud83c\udf89\ud83d\ude80",description:"",section:"News"},{id:"news-going-to-be-one-of-tas-for-the-course-advanced-deep-learning-in-b4-2024-at-university-of-copenhagen",title:"\ud83e\udd70 Going to be one of TAs for the course **Advanced Deep Learning** in B4-2024 at University of Copenhagen.",description:"",section:"News"},{id:"news-congrats-to-me-for-passing-the-courses-medical-image-analysis-advanced-topics-in-image-analysis-and-project-of-research-in-self-supervised-learning-methods-for-longitudinal-images-with-10-out-of-12",title:"\ud83e\udd73 Congrats to me for passing the courses **Medical Image Analysis**, **Advanced Topics in Image Analysis**, and **Project of Research in Self-Supervised Learning Methods for Longitudinal Images** with **10 out of 12**.",description:"",section:"News"},{id:"news-i-am-happy-to-share-i-got-12-out-of-12-in-the-courses-of-advanced-algorithms-and-data-structures-signal-and-image-processing-and-advanced-deep-learning",title:"\ud83c\udf7b I am happy to share I got **12 out of 12** in the courses of **Advanced Algorithms and Data Structures**, **Signal and Image Processing**, and **Advanced Deep Learning**.",description:"",section:"News"},{id:"news-learning-notes-advanced-algorithms-and-data-structures-https-liuying-1-github-io-blog-tag-aads-signal-and-image-processing-https-liuying-1-github-io-blog-tag-sip-and-advanced-computer-systems-https-liuying-1-github-io-blog-tag-acs-have-been-transferred-from-my-self-developed-website-to-this-one",title:"\ud83d\udcd4 Learning notes [**Advanced Algorithms and Data Structures**](https://liuying-1.github.io/blog/tag/aads), [**Signal and Image Processing**](https://liuying-1.github.io/blog/tag/sip), and [**Advanced Computer Systems**](https://liuying-1.github.io/blog/tag/acs) have been transferred from my self-developed website to this one.",description:"",section:"News"},{id:"projects-project-1",title:"project 1",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-project-2",title:"project 2",description:"a project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"projects-project-3-with-very-long-name",title:"project 3 with very long name",description:"a project that redirects to another website",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"projects-project-4",title:"project 4",description:"another without an image",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"projects-project-5",title:"project 5",description:"a project with a background image",section:"Projects",handler:()=>{window.location.href="/projects/5_project/"}},{id:"projects-project-6",title:"project 6",description:"a project with no image",section:"Projects",handler:()=>{window.location.href="/projects/6_project/"}},{id:"projects-project-7",title:"project 7",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/7_project/"}},{id:"projects-project-8",title:"project 8",description:"an other project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/8_project/"}},{id:"projects-project-9",title:"project 9",description:"another project with an image \ud83c\udf89",section:"Projects",handler:()=>{window.location.href="/projects/9_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%6C%79%35%38%31%30%39%39@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/liu-ying-463ab925b","_blank")}},{id:"socials-facebook",title:"Facebook",section:"Socials",handler:()=>{window.open("https://facebook.com/100085288350390","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js"></script> </body> </html>