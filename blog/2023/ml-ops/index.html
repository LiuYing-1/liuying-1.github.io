<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="googlece17f0a456a89a36.html"> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Neural Network II | MLOps | Y. Liu </title> <meta name="author" content="Y. Liu"> <meta name="description" content="This is the lecture for Neural Network II and MLOps."> <meta name="keywords" content="ku, ucph, copenhagen, diku, portfolio-website, liuying, dk, yingliu, ying liu, liu ying"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon.png?157bbd74cef60250fd5a67a2e078966e"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://liuying-1.github.io/blog/2023/ml-ops/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js" integrity="sha256-rjmgmaB99riUNcdlrDtcAiwtLIojSxNyUFdl+Qh+rB4=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "Neural Network II | MLOps",
            "description": "This is the lecture for Neural Network II and MLOps.",
            "published": "April 29, 2023",
            "authors": [
              
              {
                "author": "Ying Liu",
                "authorURL": "https://di.ku.dk/Ansatte/forskere/?pure=da/persons/762476",
                "affiliations": [
                  {
                    "name": "DIKU, UCPH",
                    "url": ""
                  }
                ]
              }
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Y.</span> Liu </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">Ctrl K <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>Neural Network II | MLOps</h1> <p>This is the lecture for Neural Network II and MLOps.</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div> <a href="#neural-network-ii">Neural Network II</a> </div> <ul> <li> <a href="#symbolic-differentiation">Symbolic differentiation</a> </li> <li> <a href="#mini-batch-learning">Mini-batch learning</a> </li> <li> <a href="#vanishing-gradient">Vanishing gradient</a> </li> <li> <a href="#efficient-gradient-based-optimization">Efficient gradient-based optimization</a> </li> <li> <a href="#basic-problem">Basic problem</a> </li> <li> <a href="#rescaling-by-second-raw-moment-i">Rescaling by second raw moment I</a> </li> <li> <a href="#rescaling-by-second-raw-moment-ii">Rescaling by second raw moment II</a> </li> <li> <a href="#rescaling-by-second-raw-moment-iii">Rescaling by second raw moment III</a> </li> <li> <a href="#rmsprop-adam">RMSprop | Adam</a> </li> <li> <a href="#mlops">MLOps</a> </li> </ul> <div> <a href="#reference">Reference</a> </div> </nav> </d-contents> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/MLOps.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h3 id="neural-network-ii">Neural Network II</h3> <p>Here we go!</p> <h4 id="symbolic-differentiation">Symbolic differentiation</h4> <p>Many modern machine learning frameworks can compute gradients automatically, and this might lead to a large amout of intermediate variables which causes the increase of the computational expense and memory.</p> <p>To solve this, some frameworks introduce dynamic computation graph which can avoid the case, and are more efficient than bp.</p> <h4 id="mini-batch-learning">Mini-batch learning</h4> <p><strong>Batch learning</strong>: Compute the gradients over <u>all</u> $N$ <u>training samples</u> and update</p> \[\begin{equation} \Delta \boldsymbol{w}^{(t)} = -\eta\nabla E \vert_{\boldsymbol w^{(t)}} \nonumber \end{equation}\] <p>Use <u>all data</u> to compute the gradient during <u>one iteration</u>.</p> <p><strong>Mini-batch learning</strong>: Choose a subset</p> \[\begin{align} S_m &amp; = \{(\boldsymbol{x_{i_1}, y_{i_1}}), ..., (\boldsymbol{x_{i_B}, y_{i_B}}) \} \nonumber \\ &amp; 1\leq i_1 \le ... \leq i_B \leq B \leq N \nonumber \end{align}\] <p>and update</p> \[\Delta\boldsymbol{w}^{(t)} = -\eta \sum_{(\boldsymbol{x}_n, \boldsymbol{y}_n)\in S_B}\nabla E^n \vert_\boldsymbol{w}^{(t)}\] <p>Typically with a smaller learning rate $\eta \leq 0.1$.</p> <p>Take <u>a subset of all data</u> during <u>one iteration</u>.</p> <h4 id="vanishing-gradient">Vanishing gradient</h4> <p><em>Why we need to pay attention to the range of derivatives of activation functions?</em> $Df$</p> <p>In the neural network, activation function is applied to convey the messages. When training the network, we need to update the weights (parameters) by the loss function, which involves computing $\frac{\partial E}{\partial w}$ for each $w$.</p> <p>Therefore, if the $\frac{\partial E}{\partial f}$ is too small, then, $\frac{\partial f}{\partial w}$ becomes much smaller in the back propagation and leading to “vanishing gradient” when increasing the number of layers.</p> \[\text{Target:} \frac{\partial E}{\partial w} = \frac{\partial E}{\partial f}\cdot\frac{\partial f}{\partial w}\] <p>$\implies$ weights for front layers almost without updates due to the gradient</p> <p><u>The selection of activation functions is important.</u></p> \[\begin{align} \text{Sigmoid:} &amp; \frac{\partial E}{\partial f} = Dh \leq 0.25\nonumber \\ \text{ReLU:} &amp; \frac{\partial E}{\partial f} = Dh = \begin{cases}0, &amp; \text{if $a &lt; 0$} \\ 1, &amp; \text{if $a &gt; 0$} \end{cases} \nonumber \end{align}\] <p>Hence, ReLU is more widely-used and suitable for deep learning.</p> <h4 id="efficient-gradient-based-optimization">Efficient gradient-based optimization</h4> <p>Vanilla steepest-descent is usually not the best choice for (batch) gradient-based learning. (Batch Gradient Descent: BGD)</p> <div align="center"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/JDxNxtV.png" class="img-fluid rounded z-depth-1" data-zoomable=""> </div> </div> </div> <div class="caption"> Figure 1. Example to illustrate steepest gradient descent (梗直哥、, 2021) </div> <p>Even though BGD can find the global minimum, but due to its feature by using the whole batch, its expense for <u>computation is extremely expensive</u> and <u>time consuming</u>.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/7NxwlaH.png" class="img-fluid rounded z-depth-1" data-zoomable=""> </div> </div> <div class="caption"> Figure 2. Pros and Cons for BGD (梗直哥、, 2021) </div> <h4 id="basic-problem">Basic problem</h4> <div align="center"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/yQusNi3.png" class="img-fluid rounded z-depth-1" data-zoomable=""> </div> </div> </div> <div class="caption"> Figure 3. Basic Problem (Christian, 2022) </div> <p>How to update the weights in the network to make the output close to the expected?</p> <p>Figure 3 indicates the local shape for the loss function with respect to the weights. Plateau and Ravine.</p> <p>In the plateau, the gradient for loss function is small, we need small step (learning rate) to reach the local minimum and this may lead the algorithm cannot continue to the global minimum. While for the ravine, its gradient is large which means we need to take larger step. However, it may lead to un-convergency because of the skip of the minimum. $\Leftarrow$ fixed step (learning rate)</p> <p>To solve this, the idea is,</p> <p>instead of <u>directly using the magnitude</u> of the partial derivative - to adjust the update in the <u>direction of the partial derivative</u> for each weight <u>individually based on feedback from previous iterations</u>.</p> <hr> <p>If we directly use the magnitude of the partial derivative to update the weights in each iteration, we may end up with some issues such as convergence to suboptimal solutions or overshooting the optimal solution.This is because the magnitude of the gradient alone does not always provide us with the right direction to move towards the minimum of the loss function. $\Leftarrow$ Update the weights by taking the direction from previous iterations into account.</p> <hr> <h4 id="rescaling-by-second-raw-moment-i">Rescaling by second raw moment I</h4> <p>Overview: It is a technique used in optimization algorithms, such as RMSprop and Adam, to <u>adaptively adjust the learning rate for each weight</u> in the neural network.</p> <p>The second raw moment, also known as the <u>variance</u>, measures <u>the spread of the gradient values for each weight over time</u>. By rescaling the learning rate with the inverse square root of the variance, the <u>optimization algorithm</u> can effectively <u>dampen the learning rate for weights with high variance</u> (i.e., large fluctuations in the gradient values) and <u>amplify the learning rate for weights with low variance</u> (i.e., consistent gradient values). This can help the optimization algorithm to <u>converge faster and more reliably</u>.</p> <p>Goal: Iterative minimization of $f(\boldsymbol{w})$</p> <p>Taylor approximation:</p> \[f(\boldsymbol{w+\Delta w}) \approx f(\boldsymbol{w}) + \Delta w ^{\intercal} \nabla f(\boldsymbol{w})\] <p>leads to update step</p> \[\boldsymbol{w}_i^{(t+1)} \leftarrow \boldsymbol{w}_i^{(t)} + \Delta {\boldsymbol{w}}^{(t)}\] <p>in iteration $t$</p> \[\Delta \boldsymbol{w}^{(t)} = \arg\min_{\Delta \boldsymbol{w}} \{\Delta\boldsymbol w^\intercal \nabla f(\boldsymbol w^{(t)}) \text{ s.t. } \vert\vert\Delta\boldsymbol{w}^{(t)}\vert\vert \leq \alpha \} \implies Direction\] <p>where $\alpha$ defines a trust region (in which we trust the approximation)</p> <hr> <p>The goal of iteratively minimizing a function using the Taylor approximation.</p> <p>The Taylor approximation is used to <u>derive an update step in each iteration</u>, which involves <u>finding the optimal change in weight values while restricting their magnitude to a certain trust region</u> defined by a parameter alpha.</p> <p>The ultimate goal is to find the weight values that minimize the given function, and the rescaling by second raw moment is one technique that can be used to improve the convergence of the optimization process.</p> <p>在这个方法中，我们使用Taylor展开来近似$f(\boldsymbol{w+\Delta w})$，然后将其代入到梯度下降的更新公式中，得到一个二次函数，进而利用二次函数的最小值来计算参数更新量$\Delta\boldsymbol w^{(t)}$。其中，通过引入一个trust region的概念，我们限制了参数更新的范围，使得更新量不会太大，也不会太小。这个trust region就是由$\alpha$来定义的。</p> <hr> <p>Solution is <u>co-linear with gradient</u> and has <u>maximum length</u>:</p> \[\Delta \boldsymbol{w}^{(t)} = -\alpha \frac{\nabla f\left(\boldsymbol{w}^{(t)} \right)}{\vert\vert \nabla f\left(\boldsymbol{w}^{(t)} \right)\vert\vert} \implies Length\] <h4 id="rescaling-by-second-raw-moment-ii">Rescaling by second raw moment II</h4> <p>We have <u>unbiased estimates</u> $\nabla \widetilde{f}({\boldsymbol{w}^{(t)}})$ instead of $\nabla f(\boldsymbol{w})^{(t)}$, typically gradients computed on mini-batches:</p> \[\boldsymbol{\Delta w} = -\alpha \frac{\mathbb{E}[\nabla \widetilde f(\boldsymbol{w})^{(t)}]}{\vert\vert \mathbb{E}[\nabla \widetilde f(\boldsymbol{w})^{(t)}]\vert\vert} = -\alpha \frac{\mathbb{E}[\nabla \widetilde f(\boldsymbol{w})^{(t)}]}{\sqrt{\mathbb{E}[\nabla \widetilde f(\boldsymbol{w})^{(t)]^\intercal} \mathbb{E}[\nabla \widetilde f(\boldsymbol{w})^{(t)}]}}\] <p>Concretely, for neural networks $\nabla_i \widetilde{f}\left(\boldsymbol{w}^{(t)}\right)$ is the partial derivative of the error function <u>estimate</u> (the error over mini-batch) w.r.t. weight $w_i$ at iteration $t$</p> <hr> <p>This section is discussing the second method of rescaling by second raw moment. In this method, instead of using the full gradient $\nabla f(\boldsymbol{w})^{(t)}$, we use <u>unbiased estimates of the gradient</u>, denoted as $\nabla \widetilde{f}({\boldsymbol{w}^{(t)}})$, typically computed on mini-batches.</p> <p>The formula for updating the weights in this method is given by:</p> \[\boldsymbol{\Delta w} = -\alpha \frac{\mathbb{E}[\nabla \widetilde f(\boldsymbol{w})^{(t)}]}{\vert\vert \mathbb{E}[\nabla \widetilde f(\boldsymbol{w})^{(t)}]\vert\vert} = -\alpha \frac{\mathbb{E}[\nabla \widetilde f(\boldsymbol{w})^{(t)}]}{\sqrt{\mathbb{E}[\nabla \widetilde f(\boldsymbol{w})^{(t)]^\intercal} \mathbb{E}[\nabla \widetilde f(\boldsymbol{w})^{(t)}]}}\] <p>This formula calculates the update step $\Delta \boldsymbol{w}$ as a scaled version of the expected value of the unbiased estimates of the gradient, divided by the square root of the expected value of the dot product of these estimates. In neural networks, the partial derivative of the error function estimate (the error over mini-batch) with respect to weight $w_i$ at iteration $t$ is denoted as $\nabla_i \widetilde{f}\left(\boldsymbol{w}^{(t)}\right)$.</p> <hr> <h4 id="rescaling-by-second-raw-moment-iii">Rescaling by second raw moment III</h4> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/fHoQ9SH.png" class="img-fluid rounded z-depth-1" data-zoomable=""> </div> </div> <div class="caption"> Figure 4. Rescaling by second raw moment III (Christian, 2022) </div> <h4 id="rmsprop--adam">RMSprop | Adam</h4> <p>I don’t understand the following two. I will leave them in the below and figure them out later.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/Zv90wlq.png" class="img-fluid rounded z-depth-1" data-zoomable=""> </div> </div> <div class="caption"> Figure 5. RMSprop (Christian, 2022) </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/QHJU50h.png" class="img-fluid rounded z-depth-1" data-zoomable=""> </div> </div> <div class="caption"> Figure 6. Adam Algorithm (Christian, 2022) </div> <h4 id="mlops">MLOps</h4> <p>First, what is <strong><em>DevOps</em></strong>?</p> <blockquote> <p>DevOps integrates and automates the work of software development (Dev) and IT operations (Ops) as a means for improving and shortening the systems developement life cycle. (Courtemanche, Mell, Emily, Gills, Alxander, 2023)</p> </blockquote> <p>Then, MLOps refers to the practice of applying DevOps principles and practices to the <em>development</em>, <em>deployment</em>, and <em>management</em> of <u>machine learning systems</u>.</p> <div align="center"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/MIWK64u.png" class="img-fluid rounded z-depth-1" data-zoomable=""> </div> </div> </div> <div class="caption"> Figure 7. Lifecycle of ML systems (Stefan, 2023) </div> <p><strong><em>ML Ops</em></strong> is <em>a set of practices</em> that aims to <u>deploy</u> and <u>maintain</u> ML systems in production reliably and efficiently.</p> <p><strong>Connections with DevOps</strong></p> <div align="center"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/odoqenP.png" class="img-fluid rounded z-depth-1" data-zoomable=""> </div> </div> </div> <div class="caption"> Figure 8. Venn diagram of connections (Stefan, 2023) </div> <p>The diagram is emphasizing the idea that <em>MLOps</em> requires a combination of expertise and collaboration from these three fields. Machine learning is the core of MLOps, as it involves <u>developing and training models</u>, while DevOps is essential for <u>deploying and managing those models in production environments</u>. Data engineering is also critical for <u>managing data pipelines and ensuring the quality and reliability of data used for training and inference</u>. By bringing together these three areas, MLOps enables the end-to-end lifecycle of machine learning applications, from development and training to deployment and management in production.</p> <hr> <p>Managing the data pipeline refers to the process of overseeing the flow of data from its source to its destination, ensuring that it is collected, processed, and stored properly. This involves tasks such as data ingestion, transformation, validation, cleaning, integration, and delivery.</p> <hr> <p>Here is the digram illustrate MLOps.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/Dtk2Nej.png" class="img-fluid rounded z-depth-1" data-zoomable=""> </div> </div> <div class="caption"> Figure 9. ML Pipelines connect data and code to produce models and predictions </div> <blockquote> <p>from https://towardsdatascience.com/ml-ops-machine-learning-as-an-engineering-discipline-b86ca4874a3f</p> </blockquote> <p>My understanding is that the green line represents the Data Engineering techniques to do with data for ML systems. Blue line represents the DevOps including developing and deploying code for the ML systems. While the middle part is the Machine Learning to support the ML systems, consists of training and predicting. All these things connected together is called MLOps.</p> <hr> <p><strong>CI/CD</strong> stands for Continuous <u>Integration/Continuous Deployment</u>. It is a set of practices and tools that help automate the process of building, testing, and deploying software applications. The main goal of CI/CD is to <u>reduce the time and effort required to deliver new features and updates to end-users</u> by streamlining the development, testing, and deployment processes.</p> <p>Continuous Integration involves <u>automatically building and testing</u> the application code every time changes are made to the code repository. This helps detect and fix issues early in the development process.</p> <p>Continuous Deployment involves automatically <u>deploying the code changes to production</u> after successful testing and verification. This ensures that the latest version of the software is always available to end-users.</p> <p>CI/CD can help teams to deliver higher-quality software faster and with more confidence, as it helps to catch errors earlier in the development process and reduces the risk of deploying buggy code to production.</p> <hr> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/W4v8Vay.png" class="img-fluid rounded z-depth-1" data-zoomable=""> </div> </div> <div class="caption"> Figure 10. Practices in Different Ops </div> <blockquote> <p>from https://towardsdatascience.com/ml-ops-machine-learning-as-an-engineering-discipline-b86ca4874a3f</p> </blockquote> <p>The table compares different practices in DevOps, Data Engineering, and MLOps. ML Ops is more advanced.</p> <h3 id="reference">Reference</h3> <p>梗直哥丶 (2021) <em>【梯度下降】3d可视化讲解通俗易懂_哔哩哔哩_bilibili</em>, <em>_哔哩哔哩_bilibili</em>. Available at: https://www.bilibili.com/video/BV18P4y1j7uH/?spm_id_from=333.337.search-card.all.click&amp;vd_source=0d4296a4bf13df96761e313b112ab192 (Accessed: April 29, 2023).</p> <p>Courtemanche, Meredith; Mell, Emily; Gills, Alexander S. <a href="https://www.techtarget.com/searchitoperations/definition/DevOps" rel="external nofollow noopener" target="_blank">“What Is DevOps? The Ultimate Guide”</a>. <em>TechTarget</em>. Retrieved 2023-01-22.</p> <p>Stefan Sommer. (2023) ADL 2023 - week 1 (Lecture Slide April 24, Apr 26 2023)</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/"></d-bibliography> <div id="giscus_thread" style="max-width: 930px; margin: 0 auto;"> <script>let giscusTheme=determineComputedTheme(),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"LiuYing-1/liuying-1.github.io","data-repo-id":"R_kgDOMScbNQ","data-category":"Announcements","data-category-id":"DIC_kwDOMScbNc4Cgruw","data-mapping":"pathname","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,e])=>giscusScript.setAttribute(t,e)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Y. Liu. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-JC70RZ57BT"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-JC70RZ57BT");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"About",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"Blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-cv",title:"CV",description:"Here is a brief overview of my academic and professional background, and hope there is something interesting for you. The more comprehensive version can be accessed by clicking the PDF icon on right top corner of this page.",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"post-line-segment-intersection",title:"Line Segment Intersection",description:"Self-learning note for CG - Line Segment Intersection.",section:"Posts",handler:()=>{window.location.href="/blog/2024/line-segment-intersection/"}},{id:"post-graduation",title:"Graduation",description:"Congratulations to my graduation from the DIKU, University of Copenhagen.",section:"Posts",handler:()=>{window.location.href="/blog/2024/graduation/"}},{id:"post-review-of-swav",title:"Review of SwAV",description:"This is the learning of the paper SwAV.",section:"Posts",handler:()=>{window.location.href="/assets/pdf/swav.pdf"}},{id:"post-review-of-simsiam",title:"Review of SimSiam",description:"This is the learning of the paper SimSiam.",section:"Posts",handler:()=>{window.location.href="/assets/pdf/SimSIAM.pdf"}},{id:"post-extracts-from-byol",title:"Extracts from BYOL",description:"Review of the paper BYOL and to extract the main points",section:"Posts",handler:()=>{window.location.href="/blog/2024/byol/"}},{id:"post-cookbook-reading-1",title:"Cookbook Reading - 1",description:"This is the first part of this book.",section:"Posts",handler:()=>{window.location.href="/blog/2024/cookbook-1/"}},{id:"post-advanced-image-registration",title:"Advanced Image Registration",description:"Self-learning note for advanced image registration.",section:"Posts",handler:()=>{window.location.href="/blog/2023/advanced-image-registration/"}},{id:"post-image-registration-basics",title:"Image Registration Basics",description:"Learning note for medical image registration.",section:"Posts",handler:()=>{window.location.href="/blog/2023/image-registration-l1/"}},{id:"post-segmentation-basics",title:"Segmentation Basics",description:"Learning note for medical image segmentation.",section:"Posts",handler:()=>{window.location.href="/blog/2023/segmentation-basics/"}},{id:"post-inpainting",title:"Inpainting",description:"Learning note for inpainting.",section:"Posts",handler:()=>{window.location.href="/blog/2023/inpainting/"}},{id:"post-magnetic-resonance",title:"Magnetic Resonance",description:"Preview of the lecture for MRI.",section:"Posts",handler:()=>{window.location.href="/blog/2023/mia-mr/"}},{id:"post-x-ray-and-ct",title:"X-ray and CT",description:"This is the first lecture of the course Medical Image Analysis at UCPH.",section:"Posts",handler:()=>{window.location.href="/blog/2023/mia-l1/"}},{id:"post-dansk-gt-0307",title:"Dansk &gt; 0307",description:"This is the learning note for my first lesson at Ucplus.",section:"Posts",handler:()=>{window.location.href="/blog/2023/dansk-week-1/"}},{id:"post-dictation-gt-the-art-of-balancing-stones",title:"Dictation &gt; The Art of Balancing Stones",description:"This is a daily dictation 2 for English improvement.",section:"Posts",handler:()=>{window.location.href="/blog/2023/the-art-of-balancing-stones/"}},{id:"post-dictation-gt-the-egg",title:"Dictation &gt; The Egg",description:"This is a daily dictation 1 for English improvement.",section:"Posts",handler:()=>{window.location.href="/blog/2023/the-egg/"}},{id:"post-neural-network-ii-mlops",title:"Neural Network II | MLOps",description:"This is the lecture for Neural Network II and MLOps.",section:"Posts",handler:()=>{window.location.href="/blog/2023/ml-ops/"}},{id:"post-neural-network",title:"Neural Network",description:"Recap of Neural Network",section:"Posts",handler:()=>{window.location.href="/blog/2023/neural-network-recap/"}},{id:"post-easter-lunch",title:"Easter Lunch",description:"This is the first time to have lunch with my Danish family at Easter.",section:"Posts",handler:()=>{window.location.href="/blog/2023/easter-lunch/"}},{id:"post-segmentation",title:"Segmentation",description:"Image Segmentation, including Hough Transform",section:"Posts",handler:()=>{window.location.href="/blog/2023/segmentation/"}},{id:"post-features",title:"Features",description:"Image feature detection and matching with application.",section:"Posts",handler:()=>{window.location.href="/assets/pdf/features.pdf"}},{id:"post-transformation",title:"Transformation",description:"Affine, Rigid, Perspective linear transformations, etc.",section:"Posts",handler:()=>{window.location.href="/assets/pdf/geometry.pdf"}},{id:"post-deconvolution",title:"Deconvolution",description:"Image Restoration by Deconvolution",section:"Posts",handler:()=>{window.location.href="/blog/2023/deconvolution/"}},{id:"post-histogram",title:"Histogram",description:"Thresholding segmentation and histogram techniques.",section:"Posts",handler:()=>{window.location.href="/blog/2023/histogram/"}},{id:"post-fourier",title:"Fourier",description:"Complex numbers and Fourier transformation.",section:"Posts",handler:()=>{window.location.href="/blog/2023/fourier/"}},{id:"post-filtering",title:"Filtering",description:"Linear and non-linear filtering, derivative operators.",section:"Posts",handler:()=>{window.location.href="/blog/2023/filtering/"}},{id:"post-convolution",title:"Convolution",description:"Pixel-wise Operations, Intensity, Transformations, Image Formation, and the Convolution Integral.",section:"Posts",handler:()=>{window.location.href="/blog/2023/convolution/"}},{id:"post-app-and-term",title:"App and Term",description:"Introduction of the Signal and Image Processing course, including the basic concepts, terminology, and applications.",section:"Posts",handler:()=>{window.location.href="/blog/2023/intro/"}},{id:"post-aads-grade",title:"AADS Grade",description:"This is to record I got 12 on the course Advanced Algorithms and Data Structures.",section:"Posts",handler:()=>{window.location.href="/blog/2023/aads-grade/"}},{id:"post-polygon-triangulation",title:"Polygon Triangulation",description:"This is the learning note for Polygon Triangulation.",section:"Posts",handler:()=>{window.location.href="/assets/pdf/polygon.pdf"}},{id:"post-approximation",title:"Approximation",description:"This is the learning note for Approximation algorithm - 1.",section:"Posts",handler:()=>{window.location.href="/assets/pdf/approx1.pdf"}},{id:"post-exact-parameterized",title:"Exact-Parameterized",description:"This is the learning note for Exact-Parameterized algorithm.",section:"Posts",handler:()=>{window.location.href="/assets/pdf/EE.pdf"}},{id:"post-npc",title:"NPC",description:"This is the learning note for NPC.",section:"Posts",handler:()=>{window.location.href="/assets/pdf/NPC.pdf"}},{id:"post-van-emde-boas-tree",title:"van Emde Boas Tree",description:"This is the learning note for vEB.",section:"Posts",handler:()=>{window.location.href="/assets/pdf/van-Emde-Boas-Trees.pdf"}},{id:"post-sad-mood",title:"Sad Mood",description:"This blog is to record my current sad mood.",section:"Posts",handler:()=>{window.location.href="/blog/2023/sad-mood/"}},{id:"post-hashing",title:"Hashing",description:"This is the learning note for Hashing.",section:"Posts",handler:()=>{window.location.href="/assets/pdf/Hashing.pdf"}},{id:"post-randomized-algorithms",title:"Randomized Algorithms",description:"This is the learning note for the Randomized Algorithms.",section:"Posts",handler:()=>{window.location.href="/assets/pdf/RA.pdf"}},{id:"post-linear-programming",title:"Linear Programming",description:"This is the learning note for the Linear Programming.",section:"Posts",handler:()=>{window.location.href="/assets/pdf/Linear-programming.pdf"}},{id:"post-max-flow",title:"Max-flow",description:"This is the learning note for the Max-flow.",section:"Posts",handler:()=>{window.location.href="/assets/pdf/Max-flow.pdf"}},{id:"post-recovery-gt-crash",title:"Recovery &gt; Crash",description:"This is the special case of the recovery when the system crashes.",section:"Posts",handler:()=>{window.location.href="/blog/2023/recovery-crash/"}},{id:"post-recovery-gt-normal",title:"Recovery &gt; Normal",description:"This is the special part for recovery and normal.",section:"Posts",handler:()=>{window.location.href="/blog/2023/recovery-normal/"}},{id:"post-experiment-recovery",title:"Experiment | Recovery",description:"Here are the chapters of Experiments and Recovery.",section:"Posts",handler:()=>{window.location.href="/blog/2023/recover/"}},{id:"post-concourrency-2",title:"Concourrency 2",description:"This is the chapter relating to concurrency control - Part 2.",section:"Posts",handler:()=>{window.location.href="/blog/2023/concurrency-2/"}},{id:"post-concourrency-1",title:"Concourrency 1",description:"This is the chapter relating to concurrency control.",section:"Posts",handler:()=>{window.location.href="/blog/2022/concurrency/"}},{id:"post-godt-nyt\xe5r",title:"Godt Nyt\xe5r",description:"The blog is to record my first New Year&#39;s Eve in Denmark!",section:"Posts",handler:()=>{window.location.href="/blog/2022/godt-nytar/"}},{id:"post-incorrect-url",title:"Incorrect URL",description:"Last time, my neighbor, whose world ranking in CSGO is the Global Elite, received a Christmas gift by his nisse.",section:"Posts",handler:()=>{window.location.href="/blog/2022/incorrect-url/"}},{id:"post-rpc-performance",title:"RPC | Performance",description:"RPC and Permance are the two topics we will cover today.",section:"Posts",handler:()=>{window.location.href="/blog/2022/rpc/"}},{id:"post-abstractions",title:"Abstractions",description:"Basic concepts of computer systems.",section:"Posts",handler:()=>{window.location.href="/blog/2022/abstractions/"}},{id:"post-tivoli-firework",title:"Tivoli Firework",description:"To accompany Jianxiang Yu, we went to the second oldest theme park worldwide, Tivoli in Denmark yesterday.",section:"Posts",handler:()=>{window.location.href="/blog/2022/tivoli-firework/"}},{id:"post-royal-guardian",title:"Royal Guardian",description:"The shift of the royal guardian in Marmorkirken.",section:"Posts",handler:()=>{window.location.href="/blog/2022/royal-gardian/"}},{id:"post-swan-nearby",title:"Swan Nearby",description:"A record to keep this swan in my memory.",section:"Posts",handler:()=>{window.location.href="/blog/2022/swan-nearby/"}},{id:"post-chef-first-time",title:"Chef First Time",description:"This is my first time being the chef to cook for my danish family!",section:"Posts",handler:()=>{window.location.href="/blog/2022/chief-first-time/"}},{id:"post-travel-to-malm\xf6",title:"Travel to Malm\xf6",description:"This is the final version of the image preprocessing with the limitation that cannot automatically crop the image in the center. However, it can work properly in normal situations. Also, this blog is used to record my trip to Malm\xf6, Sweden with Xuanlang.",section:"Posts",handler:()=>{window.location.href="/blog/2022/travel-to-malmo/"}},{id:"post-dev-progress",title:"Dev Progress",description:"In this version, the development of my blog website is already passed half. \u8fd9\u91cc\u662f\u4e2d\u6587\u5b57\u4f53\u6d4b\u8bd5\u3002",section:"Posts",handler:()=>{window.location.href="/blog/2022/dev-progress/"}},{id:"post-take-metro",title:"Take Metro",description:"This blog is to record my route from DIKU back to my dorm at 00:53 am several days ago.",section:"Posts",handler:()=>{window.location.href="/blog/2022/take-metro/"}},{id:"post-start-my-blog",title:"Start My Blog",description:"Memorize the start of the implementation of my blog-web.",section:"Posts",handler:()=>{window.location.href="/blog/2022/start-my-blog/"}},{id:"news-i-have-defended-my-master-thesis-quot-exploration-of-self-supervised-learning-methods-for-longitudinal-image-analysis-quot-and-received-my-master-39-s-degree-meanwhile-i-have-been-offered-a-job-as-an-ai-engineer-in-a-company",title:"I have defended my master thesis **&quot;Exploration of Self-Supervised Learning Methods for Longitudinal Image Analysis&quot;** and received my Master&#39;s Degree. Meanwhile, I have been offered a job as an **AI Engineer** in a company. \ud83c\udf93\ud83c\udf89\ud83d\ude80",description:"",section:"News"},{id:"news-going-to-be-one-of-tas-for-the-course-advanced-deep-learning-in-b4-2024-at-university-of-copenhagen",title:"\ud83e\udd70 Going to be one of TAs for the course **Advanced Deep Learning** in B4-2024 at University of Copenhagen.",description:"",section:"News"},{id:"news-congrats-to-me-for-passing-the-courses-medical-image-analysis-advanced-topics-in-image-analysis-and-project-of-research-in-self-supervised-learning-methods-for-longitudinal-images-with-10-out-of-12",title:"\ud83e\udd73 Congrats to me for passing the courses **Medical Image Analysis**, **Advanced Topics in Image Analysis**, and **Project of Research in Self-Supervised Learning Methods for Longitudinal Images** with **10 out of 12**.",description:"",section:"News"},{id:"news-i-am-happy-to-share-i-got-12-out-of-12-in-the-courses-of-advanced-algorithms-and-data-structures-signal-and-image-processing-and-advanced-deep-learning",title:"\ud83c\udf7b I am happy to share I got **12 out of 12** in the courses of **Advanced Algorithms and Data Structures**, **Signal and Image Processing**, and **Advanced Deep Learning**.",description:"",section:"News"},{id:"news-learning-notes-advanced-algorithms-and-data-structures-https-liuying-1-github-io-blog-tag-aads-signal-and-image-processing-https-liuying-1-github-io-blog-tag-sip-and-advanced-computer-systems-https-liuying-1-github-io-blog-tag-acs-have-been-transferred-from-my-self-developed-website-to-this-one",title:"\ud83d\udcd4 Learning notes [**Advanced Algorithms and Data Structures**](https://liuying-1.github.io/blog/tag/aads), [**Signal and Image Processing**](https://liuying-1.github.io/blog/tag/sip), and [**Advanced Computer Systems**](https://liuying-1.github.io/blog/tag/acs) have been transferred from my self-developed website to this one.",description:"",section:"News"},{id:"projects-project-1",title:"project 1",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-project-2",title:"project 2",description:"a project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"projects-project-3-with-very-long-name",title:"project 3 with very long name",description:"a project that redirects to another website",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"projects-project-4",title:"project 4",description:"another without an image",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"projects-project-5",title:"project 5",description:"a project with a background image",section:"Projects",handler:()=>{window.location.href="/projects/5_project/"}},{id:"projects-project-6",title:"project 6",description:"a project with no image",section:"Projects",handler:()=>{window.location.href="/projects/6_project/"}},{id:"projects-project-7",title:"project 7",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/7_project/"}},{id:"projects-project-8",title:"project 8",description:"an other project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/8_project/"}},{id:"projects-project-9",title:"project 9",description:"another project with an image \ud83c\udf89",section:"Projects",handler:()=>{window.location.href="/projects/9_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%6C%79%35%38%31%30%39%39@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/liu-ying-463ab925b","_blank")}},{id:"socials-facebook",title:"Facebook",section:"Socials",handler:()=>{window.open("https://facebook.com/100085288350390","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js"></script> </body> </html>