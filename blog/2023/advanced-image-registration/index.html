<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="googlece17f0a456a89a36.html"> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Advanced Image Registration | Y. Liu </title> <meta name="author" content="Y. Liu"> <meta name="description" content="Self-learning note for advanced image registration."> <meta name="keywords" content="ku, ucph, copenhagen, diku, portfolio-website, liuying, dk, yingliu, ying liu, liu ying"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link defer href="/assets/css/bootstrap-toc.min.css?6f5af0bb9aab25d79b2448143cbeaa88" rel="stylesheet"> <link rel="shortcut icon" href="/assets/img/favicon.png?157bbd74cef60250fd5a67a2e078966e"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://liuying-1.github.io/blog/2023/advanced-image-registration/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Y.</span> Liu </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">Ctrl K <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="row"> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> <div class="col-sm-9"> <div class="post"> <header class="post-header"> <h1 class="post-title">Advanced Image Registration</h1> <p class="post-meta"> Created in October 10, 2023 </p> <p class="post-tags"> <a href="/blog/2023"> <i class="fa-solid fa-calendar fa-sm"></i> 2023 </a>   ·   <a href="/blog/tag/mia"> <i class="fa-solid fa-hashtag fa-sm"></i> mia</a>   ·   <a href="/blog/category/study"> <i class="fa-solid fa-tag fa-sm"></i> study</a>   <a href="/blog/category/ucph"> <i class="fa-solid fa-tag fa-sm"></i> ucph</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <h4 id="todays-learning-objectives">Todays Learning Objectives</h4> <ul> <li> <p>What does <strong><u>regularization</u></strong> do in the context of <strong><u>registration</u></strong>?</p> <p>In the context of image registration, regularization refers to a technique used to <strong>improve</strong> the <strong>accuracy</strong> and <strong>robustness</strong> of the registration process. Here’s <strong>what regularization does</strong>:</p> <ul> <li> <strong>Control Deformation</strong>: Image registration aims to <strong><u>align two images by finding a transformation that maps one image onto the other</u></strong>. <strong><u>Regularization</u></strong> helps control the <strong><u>degree of deformation or warping allowed during this alignment</u></strong>. It <strong>prevents</strong> overly <strong><u>complex and unrealistic deformations</u></strong> that may lead to poor results.</li> <li> <strong>Penalize Irregularities</strong>: Regularization introduces <strong><u>a penalty term</u></strong> in the registration objective function. This penalty term <strong><u>discourages irregular, non-smooth deformations</u></strong>. By doing so, it <strong><u>promotes smooth and plausible transformations</u></strong> between the images.</li> <li> <strong>Balancing Trade-Off</strong>: Regularization <strong><u>strikes a balance</u></strong> between <strong><u>fitting the images together accurately</u></strong> and ensuring that the <strong><u>deformation remains physically plausible</u></strong>. Without regularization, registration can result in <strong><u>overly complex or noisy transformations</u></strong> that may not align images effectively.</li> <li> <strong>Controlling Sensitivity</strong>: It also helps control the <strong><u>sensitivity</u></strong> of the registration process <strong><u>to noise or outliers</u></strong> in the data. Regularization can make the registration process <strong><u>more stable and less prone to small variations</u></strong> in the images.</li> </ul> <p>In summary, regularization in image registration ensures that the <strong><u>alignment process is not overly complex</u></strong> and <strong><u>produces physically meaningful transformations</u></strong> that are both accurate and stable.</p> </li> <li> <p><u>Name</u> and <u>explain</u> at least two <u>clinical applications of registration</u></p> <ol> <li> <strong>Image-Guided Surgery</strong>: Image registration is widely used in surgery. It involves <strong><u>aligning preoperative medical images</u></strong> (such as CT scans or MRI scans) with the <strong><u>patient's actual anatomy</u></strong> during surgery. This allows surgeons to <strong><u>visualize the patient's internal structures</u></strong>, <strong><u>plan surgical procedures more accurately</u></strong>, and navigate in real-time during surgery. Image-guided surgery improves <strong><u>precision</u></strong> and <u>**reduces the invasiveness of procedures**</u>.</li> <li> <strong>Radiation Therapy</strong>: In radiation therapy for <strong><u>cancer treatment</u></strong>, image registration is crucial. It involves <strong><u>registering a patient's diagnostic images with images taken during the treatment</u></strong> (such as cone-beam CT scans). This ensures that <strong><u>radiation beams precisely target the tumor while sparing healthy tissues</u></strong>. Accurate registration is essential to <strong><u>maximize treatment effectiveness</u></strong> and <strong><u>minimize side effects</u></strong>.</li> </ol> </li> <li> <p>Handle <u>open data sets</u></p> <p>Handling open datasets involves <strong><u>working with publicly available datasets</u></strong> for research or educational purposes. Here’s how you can handle open datasets:</p> <ol> <li> <strong>Data Access</strong>: <strong><u>Find open datasets relevant to your research or learning objectives</u></strong>. These datasets are often available through websites, data repositories, or research organizations. Ensure that you have the necessary permissions to access and use the data.</li> <li> <strong>Data Download</strong>: <strong><u>Download the datasets</u></strong> following the provided guidelines and terms of use. Some datasets may require registration or citation, so make sure to adhere to any specific requirements.</li> <li> <strong>Data Preprocessing</strong>: Depending on the dataset, you may need to <strong><u>preprocess the data, clean it, and format it for your specific analysis or research goals</u></strong>. This step might involve data cleaning, normalization, and transformation.</li> <li> <strong>Data Analysis</strong>: <strong><u>Perform the desired data analysis</u></strong>, which could include image registration, image analysis, or other tasks related to your research or learning objectives. Ensure you follow good data analysis practices and documentation.</li> <li> <strong>Ethical Considerations</strong>: <strong><u>Always handle open datasets with ethical considerations</u></strong>. Respect privacy, follow legal regulati</li> </ol> </li> </ul> <h4 id="regularization">Regularization</h4> <p><strong>Terms</strong></p> <p><strong>Fixed Image</strong>:</p> <ul> <li>The “fixed” image is the <strong>reference image</strong> or the image that <strong>serves as the target</strong> for the registration process.</li> <li>It’s the image <strong>you want the “moving” image to be aligned</strong> with or transformed to match.</li> <li>In medical image analysis, the fixed image is often an anatomical image, such as a CT scan or an MRI scan, which provides the reference structure for alignment.</li> </ul> <p><strong>Moving Image</strong>:</p> <ul> <li>The “moving” image is the image that <strong>you want to align with the fixed image</strong>.</li> <li>It’s the image that <strong>undergoes a transformation</strong> to bring it into spatial alignment with the fixed image.</li> <li>In medical image analysis, the moving image could be another image of the same patient acquired at a different time or with a different modality.</li> </ul> <p>The goal of image registration is to <strong>find a transformation</strong> that can <strong>map or align</strong> the <strong>moving image to match the fixed image</strong> as closely as possible. This process is commonly used in fields like medical image analysis to compare images taken at different times, with different modalities, or for other clinical or research purposes. The fixed and moving images help <strong>establish a spatial relationship between different images, enabling comparisons, analyses, and clinical decision-making</strong>.</p> <p><strong>Deformation</strong> refers to the process of <strong>changing the <u>shape</u>, <u>size</u>, or <u>spatial arrangement</u> of an object or a structure</strong>. In the context of image registration, deformation typically involves <strong><u>altering the spatial configuration of an image or a part of an image</u></strong> to bring it into <strong><u>alignment with another image</u></strong>. Deformation can be applied to individual pixels or voxels within an image to achieve this alignment. It’s a fundamental concept in image registration because <strong><u>it describes how one image is modified to match the other</u></strong>.</p> <p><strong>Transformation</strong>, on the other hand, is a broader term that <strong><u>encompasses any mathematical operation</u></strong> applied to an image to change its position, orientation, scale, or shape. A transformation can be rigid (only involving translation and rotation), affine (involving translation, rotation, scaling, and shearing), or non-rigid (involving deformation). Transformation is a <strong><u>more general term</u></strong> that includes deformation as a specific case.</p> <p><strong>Deformed Moving</strong> in the context of image registration means that the <strong>“moving” image, which was originally not aligned with the “fixed” image</strong>, has undergone a deformation or transformation to achieve spatial alignment with the fixed image. This term indicates that <strong>the moving image has been modified or adjusted to fit or match the spatial characteristics of the fixed image</strong>. Deforming the moving image is a key step in the registration process, where the transformation is applied to bring the two images into spatial concordance.</p> <p>Here we have an example,</p> <div align="center"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/0MY6HKQ.png" class="img-fluid rounded z-depth-1" data-zoomable=""> </div> </div> </div> <div class="caption"> Figure 1. Fixed (reference) and moving (ongoing) images </div> <p>Here is the <strong>deformed moving</strong> image.</p> <div align="center"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/QQqviCR.png" class="img-fluid rounded z-depth-1" data-zoomable=""> </div> </div> </div> <div class="caption"> Figure 2. Deformed moving image </div> <p><strong><em>Is this a good transformation field?</em></strong></p> <p><strong>Definitely not</strong>. There are a lot of <strong>strange internal distortions</strong>. The transformation field might not be ideal or that the registration process did not achieve the desired result.</p> <p><strong><em>Solution</em></strong></p> <p><strong>Regularization</strong></p> <ul> <li>We make the algorithm <strong>pay the price</strong> for <strong>too much deformations</strong> </li> <li> <strong>Price</strong> should <strong>grow nonlinearly</strong> (better <strong>move many a little bit</strong> than <strong>one a lot</strong>)</li> </ul> <p>This phrase is explaining the <strong>rationale behind the nonlinear growth of the cost</strong>. It suggests that it’s <strong>more desirable to apply small deformations to multiple regions</strong> of an image rather than <strong>applying a very significant deformation to just one region</strong>. This is often because <strong>small deformations are more likely to preserve the overall structure and quality</strong> of the image.</p> <p>To put it simply, in image registration with regularization, the <strong>cost associated with deformation should encourage small, gradual changes across the entire image</strong> rather than allowing or favoring large, abrupt changes in just one area. The idea is to <strong>ensure that the transformation or deformation is smooth and physically meaningful</strong>, which can lead to <strong>better registration results</strong> and <strong>more realistic alignments</strong>. This approach helps <strong>prevent unrealistic distortions or artifacts</strong> in the transformed image.</p> <div align="center"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/VQqGWET.png" class="img-fluid rounded z-depth-1" data-zoomable=""> </div> </div> </div> <div class="caption"> Figure 3. Definition of points </div> <p>The idea behind is that <strong>we would like to preserve distances between</strong>:</p> <p>· Point $i, j$</p> <p>· Point from $\Omega_{i, j}$</p> <p>And we would like to <strong><u>preserve distances between points</u></strong> in original and deformed grid</p> <p>The goal of “<strong>preserving distances between points</strong>” is to ensure that, <strong>after the deformation</strong>, the <strong><u>distances or spatial relationships between points on the deformed grid remain as close as possible to the distances between the corresponding points on the original grid</u></strong>. In other words:</p> <ul> <li>If <strong><u>point A is originally a certain distance away from point B on the original grid</u></strong>, we want to ensure that <strong><u>after deformation</u></strong>, <strong><u>point A remains a similar distance away from point B on the deformed grid</u></strong>.</li> <li>This preservation of distances helps <strong><u>maintain the local structure and spatial relationships in the image</u></strong>. It ensures that important <strong><u>anatomical or structural features</u></strong> in the image <strong><u>do not get distorted or altered</u></strong> significantly during the registration process.</li> </ul> <p>Overall, this concept is fundamental in regularization during image registration. It contributes to the smoothness and physical plausibility of the deformation, preventing unrealistic warping and ensuring that the registered image accurately reflects the spatial characteristics of the original image.</p> <p><strong>Problem formulation</strong></p> <div align="center"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/P3XM5Gr.png" class="img-fluid rounded z-depth-1" data-zoomable=""> </div> </div> </div> <div class="caption"> Figure 4. Formulation of problem </div> <p><strong>Original optimization formulation:</strong></p> \[F(I, J, \theta) = \min\sum_{i, j}d\left(I(i, j) - J(x(i,j,\theta), y(i, j, \theta))\right)\] <p><strong>Formulation with regularization:</strong></p> \[F(I, J, \theta) = \min\left(\sum_{i, j}d(I(i, j) - J(x(i, j, \theta), y(i, j, \theta))\right) \\ + \lambda\sum_{i,j}\sum_{k, l\in\Omega_{i, j}}\left(((i-k)\ - (x(i, j, \theta) - x(k, l, \theta))\right)^2\] <p>We add a regularization term to <strong>give a penalty</strong>. And what will this regularization do?</p> \[\sum_{i, j} \sum_{k.l\in\Omega_{i, j}}(\left(1-sign\left((i-k)\cdot(x(i, j, \theta) - x(k, l, \theta))\right)\right) + \left(1-sign\left((j-l)\cdot(y(i, j, \theta)-y(k, l, \theta))\right)\right))\] <p>This regularization term is used to <strong><u>encourage the preservation of distances or relationships</u></strong> between neighboring points in the image grid during the registration process. It <strong><u>penalizes situations</u></strong> where the <strong><u>distances between points change significantly</u></strong> as a result of the deformation caused by the transformation parameter $\theta$.</p> <p>The term 1−sign(…) essentially <strong><u>imposes a penalty</u></strong> when the transformation causes <strong><u>significant changes in the spatial relationships between points</u></strong>. This encourages the registration process to <strong><u>produce a deformation that maintains the local structure and spatial characteristics of the image</u></strong>.</p> <p>The “folding” you mentioned likely refers to the effect of this regularization term in <strong><u>preventing excessive deformations that could distort or fold the image</u></strong>. The regularization term <strong><u>discourages such deformations</u></strong>, promoting smoother and more physically plausible transformations.</p> <p>In summary, this regularization term helps <strong><u>maintain the spatial relationships between neighboring points in the image grid</u></strong>, preventing excessive distortion during image registration.</p> <div align="center"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/LbWQENU.png" class="img-fluid rounded z-depth-1" data-zoomable=""> </div> </div> </div> <div class="caption"> Figure 5. Regularization of this term </div> <p>And here, by using regularization, we get a better deformed result.</p> <div align="center"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/tiWJyvY.png" class="img-fluid rounded z-depth-1" data-zoomable=""> </div> </div> </div> <div class="caption"> Figure 6. Regularized result </div> <h4 id="landmarks">Landmarks</h4> <p>Can we help registration of two squares?</p> <ul> <li> <p>Automatically detect square corners</p> <p>This step involves the automatic identification of corners or key points on the square objects in the images. These corners are distinctive features that can be used as landmarks for registration.</p> </li> <li> <p>Force registration to align corners</p> <ul> <li>This means using the detected square corners as constraints during the registration process. The registration algorithm will be instructed to ensure that the corners of the squares align precisely or as closely as possible.</li> <li>By “forcing” the registration to align corners, you are making it a priority to match these specific, distinctive points. This can be especially useful when you have prior knowledge of where these corners should be located in the registered image.</li> </ul> </li> </ul> <div align="center"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/fb1LYL8.png" class="img-fluid rounded z-depth-1" data-zoomable=""> </div> </div> </div> <div class="caption"> Figure 7. Landmarks </div> <p>Then we have new optimization function.</p> <div align="center"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/UzjYqzQ.png" class="img-fluid rounded z-depth-1" data-zoomable=""> </div> </div> </div> <div class="caption"> Figure 8. New optimization function </div> <p>The use of landmarks is a common technique in image registration, and it’s particularly valuable when you have objects with distinctive and easily detectable features, such as square corners. By aligning these landmarks, you can improve the registration accuracy and ensure that specific points of interest are correctly positioned in the registered image.</p> <p><strong>How to ensure the landmarks match?</strong> Validate the results by checking how closely the landmarks in the registered images match. You can calculate and evaluate the distances between corresponding landmarks to assess the quality of registration.</p> <h4 id="summary-algorithm">Summary Algorithm</h4> <ul> <li> <strong>Define algorithm settings</strong> <ul> <li>Acceptable transformations (Rigid, Affine, Non-rigid)</li> <li>Similarity measure (Mean Squares, Correlation, Mutual Information)</li> <li>Multi-resolution pyramid, grid schedule</li> <li>Regularization</li> </ul> </li> <li> <p><strong>Prepare input images</strong></p> <ul> <li>Normalization of intensities</li> <li>Rescaling</li> </ul> </li> <li> <strong>Optimization</strong> <ul> <li>Compute similarity measure over <strong>grids on both images</strong> </li> <li>Compute <strong>gradients on grid</strong> on moving image</li> <li>Move <strong>grid according to the gradients</strong> </li> <li> <strong>Deform</strong> moving image according to the <strong>grid</strong> </li> <li>Use splines to <strong>interpolate</strong> pixels outside the grid</li> </ul> </li> <li>Repeat until convergence</li> </ul> <h4 id="applications">Applications</h4> <h5 id="atlas-based-segmentation">Atlas-based segmentation</h5> <div align="center"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/haDNA69.png" class="img-fluid rounded z-depth-1" data-zoomable=""> </div> </div> </div> <div class="caption"> Figure 9. Atlas-based segmentation </div> <ul> <li> <p>Advantages:</p> <ul> <li> <p>Anatomically correct segmentation</p> <p>这意味着使用基于参考图谱的分割方法可以获得解剖学上正确的分割结果。具体来说，该方法参考了已知的解剖结构信息，因此分割结果更有可能准确地匹配到具体的解剖结构，如器官、组织或区域。这有助于提高分割的准确性，尤其是在医学图像分析中，这对于诊断和研究非常重要。</p> </li> <li> <p>Light training image requirements</p> <p>与某些其他分割方法相比，基于参考图谱的分割通常需要较少的训练图像。这意味着你不必拥有大量的标记数据来训练分割模型。相反，你可以仅使用一个或几个高质量的参考图谱，然后将其应用于其他图像，从而降低了训练数据的需求和数据标记的工作量。</p> </li> <li> <p>Invariant to the number of target objects</p> <p>这意味着这种方法的性能不受需要分割的目标对象数量的影响。你可以使用相同的参考图谱和算法来分割不同数量的目标对象，而不需要根据目标数量进行调整或重新训练。这种不变性对于处理不同图像或场景中的多个目标对象非常有用，因为它减轻了定制和调整的工作。</p> </li> </ul> </li> <li> <p>Disadvantages:</p> <ul> <li> <p>Slow</p> <p><strong>计算复杂性</strong>：基于参考图谱的分割方法通常涉及计算图像之间的配准或对准。这包括计算变换场（deformation field）以将参考图谱与目标图像对齐。这些计算在像素级别进行，特别是在非刚性（non-rigid）变换的情况下，需要大量计算。这会导致算法的复杂性和计算时间的增加。</p> <p><strong>多分辨率金字塔</strong>：虽然多分辨率金字塔可以提高配准的鲁棒性，但也会增加计算的复杂性。多分辨率金字塔需要在不同分辨率级别上执行配准，每个级别都需要计算变换场。这意味着多分辨率金字塔方法可能需要更多的计算时间。</p> <p><strong>正则化</strong>：正则化用于平滑变换场以确保物理上合理的形变，但它也会引入额外的计算。正则化通常需要迭代优化过程，这会增加计算时间。</p> <p><strong>硬件限制</strong>：图像分割通常需要大量计算资源，特别是在高分辨率或大规模数据集的情况下。如果计算资源受限，速度可能会受到限制。</p> </li> </ul> </li> </ul> <p>See details about <a href="https://liuying-1.github.io/blog/2023/image-registration-l1/">Atlas-based Segmentation</a> <img class="emoji" title=":point_left:" alt=":point_left:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f448.png" height="20" width="20"></p> <h5 id="multi-modal-image-registration">Multi-modal image registration</h5> <p>Improves <strong>visibility of structures</strong> (bones – CT, soft tissues – MR, tumors – PET and MR)</p> <p>“Multi-modal image registration” 指的是在医学图像分析中，同时注册或配准不同模态（多模态）的医学图像。<strong><u>每种模态</u></strong>的医学图像（如CT扫描、MRI扫描、PET扫描等）<strong><u>对人体结构和病变有不同的灰度值、对比度和信息</u></strong>。”Improves visibility of structures” 的意思是<strong><u>多模态图像配准可以改善不同模态下的结构可视性</u></strong>。</p> <p>具体来说，这些不同模态的图像可能有以下特点：</p> <div align="center"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/SBq4Pxv.png" class="img-fluid rounded z-depth-1" data-zoomable=""> </div> </div> </div> <div class="caption"> Figure 10. Soft-tissues </div> <ol> <li> <p><strong>CT图像</strong>：在CT扫描中，<strong><u>骨骼结构</u></strong>通常显示得很清晰，因为它们有高对比度。然而，对软组织的可视性可能较差。</p> </li> <li> <p><strong>MR图像</strong>：MRI图像对于显示<strong><u>软组织结构</u></strong>非常出色，但对于骨骼结构的可视性可能不如CT。</p> <div align="center"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/HKTrqHQ.png" class="img-fluid rounded z-depth-1" data-zoomable=""> </div> </div> </div> <div class="caption"> Figure 11. Bones </div> </li> <li> <p><strong>PET图像</strong>：PET扫描用于检测代谢活跃性，通常用于<strong><u>肿瘤诊断</u></strong>。PET图像可以显示<strong><u>肿瘤</u></strong>和其他异常的生物活动，但对解剖结构的细节可视性相对较低。</p> <div align="center"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/VM8awXw.png" class="img-fluid rounded z-depth-1" data-zoomable=""> </div> </div> </div> <div class="caption"> Figure 12. Tumors </div> </li> </ol> <p>“Multi-modal image registration” 允许将这些不同模态的图像进行配准，以便在同一坐标系下对比它们。这样做有以下好处：</p> <ul> <li> <strong>改善可视性</strong>：通过将不同模态的图像进行配准，你可以在一个图像中同时显示不同模态下的结构。例如，你可以在同一图像中清晰地看到骨骼（来自CT图像）、软组织（来自MR图像）和肿瘤活性（来自PET图像），从而获得更全面的信息。</li> <li> <strong>指导诊断和治疗</strong>：多模态配准可帮助医生更准确地诊断病症、规划手术和监测治疗进展。医生可以在一个图像上同时查看多个信息来源，有助于更全面地了解患者的情况。</li> </ul> <p>总之，多模态图像配准有助于提高医学图像的可视性，增加信息的融合，从而更好地支持医疗诊断和治疗过程。</p> <p>多模态图像配准是将来自不同图像模态的图像进行对齐，以使它们在同一坐标系下对应到相同的解剖结构或区域。这种配准的目的是允许医生或研究人员同时查看不同模态下的图像信息，从而更全面地理解患者的情况。以下是多模态图像配准的一般流程：</p> <ol> <li> <strong>图像获取</strong>：首先，不同模态的图像（例如CT、MRI、PET等）必须分别获取。这些图像通常在不同的设备上获得，具有不同的对比度和信息。</li> <li> <strong>图像预处理</strong>：在进行配准之前，通常需要对图像进行预处理，包括去噪、增强、图像校正等操作，以确保它们处于最佳状态。</li> <li> <strong>特征提取</strong>：从每种模态的图像中<strong><u>提取特征</u></strong>，这些特征可以是解剖结构、标记点或其他在不同模态下容易识别的图像特征。特征提取是关键的一步，因为<strong><u>它确定了配准过程中用于对齐的关键点</u></strong>。</li> <li> <strong>特征匹配</strong>：在不同模态图像中提取的特征进行匹配。这可以通过各种计算机视觉算法实现，通常是在配准算法中的一个步骤。特征匹配的目标是找到相应的特征点，以便进行配准。</li> <li> <strong>配准变换</strong>：<strong><u>基于找到的特征匹配，计算需要应用于其中一个图像以使其与另一个图像对齐的变换</u></strong>。这可以是刚性、仿射或非刚性变换，具体取决于图像的类型和所需的对齐程度。</li> <li> <strong>配准优化</strong>：进行迭代优化，以确保变换能够最好地对齐图像。这包括优化变换参数以最小化特征点之间的距离或匹配误差。</li> <li> <strong>生成配准后的图像</strong>：应用配准变换，将不同模态的图像对齐到同一坐标系下，从而生成配准后的图像。这些图像可以同时查看，以获得更多信息。</li> </ol> <p>需要注意的是，多模态图像配准是一项复杂的任务，其复杂性取决于图像的特性和所使用的配准算法。它通常需要计算机视觉和图像处理领域的专业知识，以确保高质量的配准结果。这种配准方法在医学影像学、医学诊断和研究中具有广泛的应用。</p> <h5 id="atlas-based-abnormality-detection">Atlas-based abnormality detection</h5> <div align="center"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/wFbSCgB.png" class="img-fluid rounded z-depth-1" data-zoomable=""> </div> </div> </div> <div class="caption"> Figure 13. Abnormality detection </div> <ul> <li>Register <strong><u>healthy</u></strong> image to <strong><u>potentially abnormal</u></strong> </li> <li>Study deformation field to <strong><u>find abnormalities</u></strong> </li> </ul> <p>“Atlas-based abnormality detection” 是一种用于检测医学图像中异常或病变的方法，它基于已知的正常解剖结构的图谱（atlas）来识别图像中的异常情况。</p> <ol> <li> <strong>图谱（Atlas）</strong>：图谱是一组已知正常解剖结构的参考图像。这些图像通常来自大量的<strong><u>健康患者</u></strong>，用于表示<strong><u>正常的生理结构</u></strong>和器官。图谱可以包括各种模态的图像，如CT、MRI等。</li> <li> <strong>异常检测</strong>：在医学图像中，异常通常是指与正常解剖结构不同的区域，可能是疾病、损伤或其他异常情况的迹象。异常可以表现为异常的形状、密度、亮度或其他特征。</li> <li> <strong>配准与对比</strong>：在进行异常检测时，首先将<strong><u>待检测图像（可能是患者的图像）与正常图谱</u></strong>进行配准。这意味着将待检测图像中的结构与图谱中的对应结构对齐。</li> <li> <strong>特征提取</strong>：一旦完成配准，就可以从待检测图像中提取特征，这些特征通常是与异常相关的特征，如区域的形状、密度、纹理等。</li> <li> <strong>异常检测算法</strong>：使用特征和已知的正常图谱作为参考，异常检测算法可以<strong><u>识别待检测图像中与正常图谱不匹配</u></strong>的区域。这些不匹配的区域可能表示异常或病变。</li> <li> <strong>可视化和报告</strong>：检测到的异常区域可以用于生成可视化结果，供医生或研究人员查看。异常检测的结果通常以可视化图像或报告的形式呈现。</li> </ol> <p>“Atlas-based abnormality detection” 的优势在于它依赖于已知的正常图谱作为参考，因此可以帮助<strong><u>快速识别潜在的异常区域</u></strong>。这对于医学诊断、疾病筛查和研究非常有用，因为它可以帮助医生或研究人员更快速地识别异常，而不需要手动检查整个图像。</p> <p>在 “Atlas-based abnormality detection” 中，通常采取的方法包括：</p> <ol> <li> <strong>将健康图像配准到潜在异常图像</strong>：首先，将一个或多个健康图像（正常图谱）与潜在异常图像进行配准，以使它们在相同的坐标系下对齐。这意味着<strong><u>将健康图像中的正常结构与潜在异常图像对应的结构对齐</u></strong>。</li> <li> <strong>研究变换场以发现异常</strong>：<strong><u>一旦进行了配准，就可以研究变换场</u></strong>（deformation field）。变换场表示<strong><u>从健康图像到潜在异常图像的变换</u></strong>，它描述了<strong><u>正常结构在潜在异常图像中的形变</u></strong>。通过<strong><u>分析变换场</u></strong>，可以<strong><u>识别出在潜在异常图像中与正常结构不匹配</u></strong>的区域。</li> </ol> <p>这个方法的思想是，通过将健康图像与潜在异常图像对齐，可以将正常结构的位置和形状信息传递到潜在异常图像中。然后，通过比较正常结构的期望位置和实际位置（通过变换场表示），可以检测到异常或病变区域，因为这些区域可能会产生异常的形变。</p> <p>这种方法在医学图像中用于异常检测，特别是在需要自动识别潜在异常或病变的情况下，具有重要的应用潜力。</p> <div align="center"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/itVoHD4.png" class="img-fluid rounded z-depth-1" data-zoomable=""> </div> </div> </div> <div class="caption"> Figure 14. Small abnormalities </div> <ul> <li>Problem <ul> <li>Difficult to detect small abnormalities</li> </ul> </li> </ul> <p>“Difficult to detect small abnormalities” 意味着在某些情况下，使用基于图谱的方法来检测小尺寸异常或病变可能面临挑战。这可能是因为以下原因：</p> <ol> <li> <strong>空间分辨率限制</strong>：医学图像的空间分辨率是有限的，特别是对于某些成本昂贵的成像技术。小尺寸的异常可能在图像中占据的像素数量很少，因此可能难以在低分辨率图像中准确检测。</li> <li> <strong>噪声和伪影</strong>：医学图像可能受到噪声和伪影的影响，这些因素可以干扰小异常的检测。噪声可以导致虚假的异常检测，而伪影可能使异常区域难以分辨。</li> <li> <strong>特征提取的挑战</strong>：检测小异常通常需要更高级别的特征提取和分析，以便捕捉细微的变化。这可能需要更复杂的算法和更多的计算资源。</li> </ol> <p>解决这个问题的方法可能包括：</p> <ul> <li> <strong>提高图像分辨率</strong>：使用更高分辨率的成像技术可以帮助更准确地检测小尺寸的异常。</li> <li> <strong>降低噪声</strong>：采取噪声抑制技术，以减少噪声对异常检测的干扰。</li> <li> <strong>使用多模态信息</strong>：结合不同模态的图像信息，以提高对小异常的检测能力。</li> <li> <strong>使用深度学习方法</strong>：深度学习技术在医学图像分析中表现出色，可以帮助检测小异常，因为它们可以自动学习图像中的特征。</li> </ul> <p>综合来说，检测小异常是医学图像分析中的一个挑战，但可以通过改进图像质量、采用高级分析方法以及使用多种信息源来应对这一挑战。</p> <h5 id="super-resolution-images">Super-resolution images</h5> <p>We have three orthogonal 3D MR images of high in-plane resolution but high slice thickness. How to create a super-resolution 3D MR?</p> <div align="center"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/AfM6SVk.png" class="img-fluid rounded z-depth-1" data-zoomable=""> </div> </div> </div> <div class="caption"> Figure 15. Super-resolution </div> <p>创建超分辨率 3D MR 图像通常涉及将现有的低分辨率图像增强到高分辨率图像的过程。在这种情况下，你拥有三个不同方向（x、y、z）的 3D MR 图像，这些图像具有高平面分辨率，但在切片（z轴方向）上的分辨率较低。下面是一种可能的方法来创建超分辨率 3D MR 图像：</p> <ol> <li> <strong>数据预处理</strong>：首先，对你的三个 3D MR 图像进行数据预处理。这包括去噪、伪影去除、校正以及确保它们已经在相同的坐标系下对齐。</li> <li> <strong>切片插值</strong>：在 3D MR 图像的切片方向上，由于分辨率较低，你可以使用插值方法来增加切片数量，从而提高 z 轴分辨率。这可以采用一维插值方法，例如线性插值或样条插值。这将生成一系列新的切片，以增加在 z 轴方向上的分辨率。</li> <li> <strong>3D 重建</strong>：一旦你获得了高分辨率切片，可以将它们组合成 3D 数据卷。这可以通过采用体绘图（Volume Rendering）或通过堆叠这些切片来实现。这将生成一个具有更高分辨率的 3D MR 图像。</li> <li> <strong>超分辨率技术</strong>：如果你希望进一步增加图像的分辨率，可以使用超分辨率技术。这些技术基于统计方法、深度学习或其他算法，可以通过分析图像的细节来生成更高分辨率的版本。这需要具体的超分辨率算法，并可能需要使用额外的训练数据。</li> <li> <strong>评估和验证</strong>：最后，一定要评估和验证生成的超分辨率图像的质量。这可以通过与高分辨率图像进行比较，或者使用图像质量指标来进行评估。</li> </ol> <p>需要注意的是，超分辨率图像的质量取决于数据的质量、使用的插值和重建方法，以及是否使用了超分辨率算法。这是一个复杂的过程，通常需要在医学影像领域具有专业知识的人员来执行。</p> <ul> <li>We convert orthogonal images to full volume but adding empty space</li> <li>This empty space should not be taken into account during registration</li> <li>Idea of masked registration</li> </ul> <p>在创建超分辨率 3D MR 图像时，将正交图像转换为完整的体积并添加空白空间是一个常见的方法。这种空白空间不应该在图像配准过程中考虑在内，因为它仅是为了在 z 轴方向上增加分辨率而添加的。</p> <p>以下是关于如何执行这一过程的一般步骤：</p> <ol> <li> <strong>创建完整的 3D MR 体积</strong>：将正交图像（高分辨率但切片分辨率较低）转换为完整的 3D MR 体积。这可以通过在切片方向上重复图像来实现，以填充空白空间。这将生成一个完整的 3D 数据卷，包括原始图像和添加的空白切片。</li> <li> <strong>生成掩模（Mask）</strong>：为了确保在图像配准期间不考虑空白切片，你可以生成一个掩模，其中空白切片被标记为不感兴趣区域。掩模通常是一个与图像体积具有相同尺寸的 3D 数据，其中正值表示感兴趣区域，负值或零表示不感兴趣区域（即空白切片）。</li> <li> <strong>掩模配准</strong>：在进行图像配准时，你可以使用掩模来指定感兴趣区域。这意味着只有非空白部分的图像将被用于配准，而空白部分将被忽略。这有助于提高配准的准确性，因为配准算法将集中在包含有用信息的部分。</li> <li> <strong>生成高分辨率 3D 图像</strong>：一旦完成配准，可以生成具有更高 z 轴分辨率的 3D MR 图像。这可以通过将正交图像的 z 轴方向上的高分辨率信息与掩模应用于已配准的体积来实现。</li> <li> <strong>评估和验证</strong>：最后，一定要评估和验证生成的超分辨率 3D 图像的质量，以确保它满足你的需求。</li> </ol> <p>这种方法允许你在 z 轴方向上增加分辨率，同时保留了 x 和 y 轴方向上的高分辨率信息。使用掩模来指定感兴趣区域是一个有用的技巧，以确保只有有用的信息用于图像配准和超分辨率生成。</p> <div align="center"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/GoKFaDW.png" class="img-fluid rounded z-depth-1" data-zoomable=""> </div> </div> </div> <div class="caption"> Figure 16. Super-resolution - 2 </div> <p>I didn’t get the points here, and there are some other applications afterwards, but I am not going to explore them in detail, for instance, <strong>Adaptive radiotherapy planning</strong>, <strong>Landmark-based registration</strong>, and <strong>2D-3D registration</strong>.</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/line-segment-intersection/">Line Segment Intersection</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/graduation/">Graduation</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/swav/">Review of SwAV</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/simsiam/">Review of SimSiam</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/byol/">Extracts from BYOL</a> </li> <div id="giscus_thread" style="max-width: 930px; margin: 0 auto;"> <script>let giscusTheme=determineComputedTheme(),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"LiuYing-1/liuying-1.github.io","data-repo-id":"R_kgDOMScbNQ","data-category":"Announcements","data-category-id":"DIC_kwDOMScbNc4Cgruw","data-mapping":"pathname","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,e])=>giscusScript.setAttribute(t,e)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Y. Liu. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="/assets/js/bootstrap-toc.min.js?c82ff4de8b0955d6ff14f5b05eed7eb6"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js" integrity="sha256-rjmgmaB99riUNcdlrDtcAiwtLIojSxNyUFdl+Qh+rB4=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-JC70RZ57BT"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-JC70RZ57BT");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"About",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"Blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-cv",title:"CV",description:"Here is a brief overview of my academic and professional background, and hope there is something interesting for you. The more comprehensive version can be accessed by clicking the PDF icon on right top corner of this page.",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"post-line-segment-intersection",title:"Line Segment Intersection",description:"Self-learning note for CG - Line Segment Intersection.",section:"Posts",handler:()=>{window.location.href="/blog/2024/line-segment-intersection/"}},{id:"post-graduation",title:"Graduation",description:"Congratulations to my graduation from the DIKU, University of Copenhagen.",section:"Posts",handler:()=>{window.location.href="/blog/2024/graduation/"}},{id:"post-review-of-swav",title:"Review of SwAV",description:"This is the learning of the paper SwAV.",section:"Posts",handler:()=>{window.location.href="/assets/pdf/swav.pdf"}},{id:"post-review-of-simsiam",title:"Review of SimSiam",description:"This is the learning of the paper SimSiam.",section:"Posts",handler:()=>{window.location.href="/assets/pdf/SimSIAM.pdf"}},{id:"post-extracts-from-byol",title:"Extracts from BYOL",description:"Review of the paper BYOL and to extract the main points",section:"Posts",handler:()=>{window.location.href="/blog/2024/byol/"}},{id:"post-cookbook-reading-1",title:"Cookbook Reading - 1",description:"This is the first part of this book.",section:"Posts",handler:()=>{window.location.href="/blog/2024/cookbook-1/"}},{id:"post-advanced-image-registration",title:"Advanced Image Registration",description:"Self-learning note for advanced image registration.",section:"Posts",handler:()=>{window.location.href="/blog/2023/advanced-image-registration/"}},{id:"post-image-registration-basics",title:"Image Registration Basics",description:"Learning note for medical image registration.",section:"Posts",handler:()=>{window.location.href="/blog/2023/image-registration-l1/"}},{id:"post-segmentation-basics",title:"Segmentation Basics",description:"Learning note for medical image segmentation.",section:"Posts",handler:()=>{window.location.href="/blog/2023/segmentation-basics/"}},{id:"post-inpainting",title:"Inpainting",description:"Learning note for inpainting.",section:"Posts",handler:()=>{window.location.href="/blog/2023/inpainting/"}},{id:"post-magnetic-resonance",title:"Magnetic Resonance",description:"Preview of the lecture for MRI.",section:"Posts",handler:()=>{window.location.href="/blog/2023/mia-mr/"}},{id:"post-x-ray-and-ct",title:"X-ray and CT",description:"This is the first lecture of the course Medical Image Analysis at UCPH.",section:"Posts",handler:()=>{window.location.href="/blog/2023/mia-l1/"}},{id:"post-dansk-gt-0307",title:"Dansk &gt; 0307",description:"This is the learning note for my first lesson at Ucplus.",section:"Posts",handler:()=>{window.location.href="/blog/2023/dansk-week-1/"}},{id:"post-dictation-gt-the-art-of-balancing-stones",title:"Dictation &gt; The Art of Balancing Stones",description:"This is a daily dictation 2 for English improvement.",section:"Posts",handler:()=>{window.location.href="/blog/2023/the-art-of-balancing-stones/"}},{id:"post-dictation-gt-the-egg",title:"Dictation &gt; The Egg",description:"This is a daily dictation 1 for English improvement.",section:"Posts",handler:()=>{window.location.href="/blog/2023/the-egg/"}},{id:"post-neural-network-ii-mlops",title:"Neural Network II | MLOps",description:"This is the lecture for Neural Network II and MLOps.",section:"Posts",handler:()=>{window.location.href="/blog/2023/ml-ops/"}},{id:"post-neural-network",title:"Neural Network",description:"Recap of Neural Network",section:"Posts",handler:()=>{window.location.href="/blog/2023/neural-network-recap/"}},{id:"post-easter-lunch",title:"Easter Lunch",description:"This is the first time to have lunch with my Danish family at Easter.",section:"Posts",handler:()=>{window.location.href="/blog/2023/easter-lunch/"}},{id:"post-segmentation",title:"Segmentation",description:"Image Segmentation, including Hough Transform",section:"Posts",handler:()=>{window.location.href="/blog/2023/segmentation/"}},{id:"post-features",title:"Features",description:"Image feature detection and matching with application.",section:"Posts",handler:()=>{window.location.href="/assets/pdf/features.pdf"}},{id:"post-transformation",title:"Transformation",description:"Affine, Rigid, Perspective linear transformations, etc.",section:"Posts",handler:()=>{window.location.href="/assets/pdf/geometry.pdf"}},{id:"post-deconvolution",title:"Deconvolution",description:"Image Restoration by Deconvolution",section:"Posts",handler:()=>{window.location.href="/blog/2023/deconvolution/"}},{id:"post-histogram",title:"Histogram",description:"Thresholding segmentation and histogram techniques.",section:"Posts",handler:()=>{window.location.href="/blog/2023/histogram/"}},{id:"post-fourier",title:"Fourier",description:"Complex numbers and Fourier transformation.",section:"Posts",handler:()=>{window.location.href="/blog/2023/fourier/"}},{id:"post-filtering",title:"Filtering",description:"Linear and non-linear filtering, derivative operators.",section:"Posts",handler:()=>{window.location.href="/blog/2023/filtering/"}},{id:"post-convolution",title:"Convolution",description:"Pixel-wise Operations, Intensity, Transformations, Image Formation, and the Convolution Integral.",section:"Posts",handler:()=>{window.location.href="/blog/2023/convolution/"}},{id:"post-app-and-term",title:"App and Term",description:"Introduction of the Signal and Image Processing course, including the basic concepts, terminology, and applications.",section:"Posts",handler:()=>{window.location.href="/blog/2023/intro/"}},{id:"post-aads-grade",title:"AADS Grade",description:"This is to record I got 12 on the course Advanced Algorithms and Data Structures.",section:"Posts",handler:()=>{window.location.href="/blog/2023/aads-grade/"}},{id:"post-polygon-triangulation",title:"Polygon Triangulation",description:"This is the learning note for Polygon Triangulation.",section:"Posts",handler:()=>{window.location.href="/assets/pdf/polygon.pdf"}},{id:"post-approximation",title:"Approximation",description:"This is the learning note for Approximation algorithm - 1.",section:"Posts",handler:()=>{window.location.href="/assets/pdf/approx1.pdf"}},{id:"post-exact-parameterized",title:"Exact-Parameterized",description:"This is the learning note for Exact-Parameterized algorithm.",section:"Posts",handler:()=>{window.location.href="/assets/pdf/EE.pdf"}},{id:"post-npc",title:"NPC",description:"This is the learning note for NPC.",section:"Posts",handler:()=>{window.location.href="/assets/pdf/NPC.pdf"}},{id:"post-van-emde-boas-tree",title:"van Emde Boas Tree",description:"This is the learning note for vEB.",section:"Posts",handler:()=>{window.location.href="/assets/pdf/van-Emde-Boas-Trees.pdf"}},{id:"post-sad-mood",title:"Sad Mood",description:"This blog is to record my current sad mood.",section:"Posts",handler:()=>{window.location.href="/blog/2023/sad-mood/"}},{id:"post-hashing",title:"Hashing",description:"This is the learning note for Hashing.",section:"Posts",handler:()=>{window.location.href="/assets/pdf/Hashing.pdf"}},{id:"post-randomized-algorithms",title:"Randomized Algorithms",description:"This is the learning note for the Randomized Algorithms.",section:"Posts",handler:()=>{window.location.href="/assets/pdf/RA.pdf"}},{id:"post-linear-programming",title:"Linear Programming",description:"This is the learning note for the Linear Programming.",section:"Posts",handler:()=>{window.location.href="/assets/pdf/Linear-programming.pdf"}},{id:"post-max-flow",title:"Max-flow",description:"This is the learning note for the Max-flow.",section:"Posts",handler:()=>{window.location.href="/assets/pdf/Max-flow.pdf"}},{id:"post-recovery-gt-crash",title:"Recovery &gt; Crash",description:"This is the special case of the recovery when the system crashes.",section:"Posts",handler:()=>{window.location.href="/blog/2023/recovery-crash/"}},{id:"post-recovery-gt-normal",title:"Recovery &gt; Normal",description:"This is the special part for recovery and normal.",section:"Posts",handler:()=>{window.location.href="/blog/2023/recovery-normal/"}},{id:"post-experiment-recovery",title:"Experiment | Recovery",description:"Here are the chapters of Experiments and Recovery.",section:"Posts",handler:()=>{window.location.href="/blog/2023/recover/"}},{id:"post-concourrency-2",title:"Concourrency 2",description:"This is the chapter relating to concurrency control - Part 2.",section:"Posts",handler:()=>{window.location.href="/blog/2023/concurrency-2/"}},{id:"post-concourrency-1",title:"Concourrency 1",description:"This is the chapter relating to concurrency control.",section:"Posts",handler:()=>{window.location.href="/blog/2022/concurrency/"}},{id:"post-godt-nyt\xe5r",title:"Godt Nyt\xe5r",description:"The blog is to record my first New Year&#39;s Eve in Denmark!",section:"Posts",handler:()=>{window.location.href="/blog/2022/godt-nytar/"}},{id:"post-incorrect-url",title:"Incorrect URL",description:"Last time, my neighbor, whose world ranking in CSGO is the Global Elite, received a Christmas gift by his nisse.",section:"Posts",handler:()=>{window.location.href="/blog/2022/incorrect-url/"}},{id:"post-rpc-performance",title:"RPC | Performance",description:"RPC and Permance are the two topics we will cover today.",section:"Posts",handler:()=>{window.location.href="/blog/2022/rpc/"}},{id:"post-abstractions",title:"Abstractions",description:"Basic concepts of computer systems.",section:"Posts",handler:()=>{window.location.href="/blog/2022/abstractions/"}},{id:"post-tivoli-firework",title:"Tivoli Firework",description:"To accompany Jianxiang Yu, we went to the second oldest theme park worldwide, Tivoli in Denmark yesterday.",section:"Posts",handler:()=>{window.location.href="/blog/2022/tivoli-firework/"}},{id:"post-royal-guardian",title:"Royal Guardian",description:"The shift of the royal guardian in Marmorkirken.",section:"Posts",handler:()=>{window.location.href="/blog/2022/royal-gardian/"}},{id:"post-swan-nearby",title:"Swan Nearby",description:"A record to keep this swan in my memory.",section:"Posts",handler:()=>{window.location.href="/blog/2022/swan-nearby/"}},{id:"post-chef-first-time",title:"Chef First Time",description:"This is my first time being the chef to cook for my danish family!",section:"Posts",handler:()=>{window.location.href="/blog/2022/chief-first-time/"}},{id:"post-travel-to-malm\xf6",title:"Travel to Malm\xf6",description:"This is the final version of the image preprocessing with the limitation that cannot automatically crop the image in the center. However, it can work properly in normal situations. Also, this blog is used to record my trip to Malm\xf6, Sweden with Xuanlang.",section:"Posts",handler:()=>{window.location.href="/blog/2022/travel-to-malmo/"}},{id:"post-dev-progress",title:"Dev Progress",description:"In this version, the development of my blog website is already passed half. \u8fd9\u91cc\u662f\u4e2d\u6587\u5b57\u4f53\u6d4b\u8bd5\u3002",section:"Posts",handler:()=>{window.location.href="/blog/2022/dev-progress/"}},{id:"post-take-metro",title:"Take Metro",description:"This blog is to record my route from DIKU back to my dorm at 00:53 am several days ago.",section:"Posts",handler:()=>{window.location.href="/blog/2022/take-metro/"}},{id:"post-start-my-blog",title:"Start My Blog",description:"Memorize the start of the implementation of my blog-web.",section:"Posts",handler:()=>{window.location.href="/blog/2022/start-my-blog/"}},{id:"news-i-have-defended-my-master-thesis-quot-exploration-of-self-supervised-learning-methods-for-longitudinal-image-analysis-quot-and-received-my-master-39-s-degree-meanwhile-i-have-been-offered-a-job-as-an-ai-engineer-in-a-company",title:"I have defended my master thesis **&quot;Exploration of Self-Supervised Learning Methods for Longitudinal Image Analysis&quot;** and received my Master&#39;s Degree. Meanwhile, I have been offered a job as an **AI Engineer** in a company. \ud83c\udf93\ud83c\udf89\ud83d\ude80",description:"",section:"News"},{id:"news-going-to-be-one-of-tas-for-the-course-advanced-deep-learning-in-b4-2024-at-university-of-copenhagen",title:"\ud83e\udd70 Going to be one of TAs for the course **Advanced Deep Learning** in B4-2024 at University of Copenhagen.",description:"",section:"News"},{id:"news-congrats-to-me-for-passing-the-courses-medical-image-analysis-advanced-topics-in-image-analysis-and-project-of-research-in-self-supervised-learning-methods-for-longitudinal-images-with-10-out-of-12",title:"\ud83e\udd73 Congrats to me for passing the courses **Medical Image Analysis**, **Advanced Topics in Image Analysis**, and **Project of Research in Self-Supervised Learning Methods for Longitudinal Images** with **10 out of 12**.",description:"",section:"News"},{id:"news-i-am-happy-to-share-i-got-12-out-of-12-in-the-courses-of-advanced-algorithms-and-data-structures-signal-and-image-processing-and-advanced-deep-learning",title:"\ud83c\udf7b I am happy to share I got **12 out of 12** in the courses of **Advanced Algorithms and Data Structures**, **Signal and Image Processing**, and **Advanced Deep Learning**.",description:"",section:"News"},{id:"news-learning-notes-advanced-algorithms-and-data-structures-https-liuying-1-github-io-blog-tag-aads-signal-and-image-processing-https-liuying-1-github-io-blog-tag-sip-and-advanced-computer-systems-https-liuying-1-github-io-blog-tag-acs-have-been-transferred-from-my-self-developed-website-to-this-one",title:"\ud83d\udcd4 Learning notes [**Advanced Algorithms and Data Structures**](https://liuying-1.github.io/blog/tag/aads), [**Signal and Image Processing**](https://liuying-1.github.io/blog/tag/sip), and [**Advanced Computer Systems**](https://liuying-1.github.io/blog/tag/acs) have been transferred from my self-developed website to this one.",description:"",section:"News"},{id:"projects-project-1",title:"project 1",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-project-2",title:"project 2",description:"a project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"projects-project-3-with-very-long-name",title:"project 3 with very long name",description:"a project that redirects to another website",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"projects-project-4",title:"project 4",description:"another without an image",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"projects-project-5",title:"project 5",description:"a project with a background image",section:"Projects",handler:()=>{window.location.href="/projects/5_project/"}},{id:"projects-project-6",title:"project 6",description:"a project with no image",section:"Projects",handler:()=>{window.location.href="/projects/6_project/"}},{id:"projects-project-7",title:"project 7",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/7_project/"}},{id:"projects-project-8",title:"project 8",description:"an other project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/8_project/"}},{id:"projects-project-9",title:"project 9",description:"another project with an image \ud83c\udf89",section:"Projects",handler:()=>{window.location.href="/projects/9_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%6C%79%35%38%31%30%39%39@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/liu-ying-463ab925b","_blank")}},{id:"socials-facebook",title:"Facebook",section:"Socials",handler:()=>{window.open("https://facebook.com/100085288350390","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js"></script> </body> </html>