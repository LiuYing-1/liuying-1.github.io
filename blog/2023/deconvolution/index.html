<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="googlece17f0a456a89a36.html"> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Deconvolution | Y. Liu </title> <meta name="author" content="Y. Liu"> <meta name="description" content="Image Restoration by Deconvolution"> <meta name="keywords" content="ku, ucph, copenhagen, diku, portfolio-website, liuying, dk, yingliu, ying liu, liu ying"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css2?family=Playfair:ital,opsz,wght@0,5..1200,300..900;1,5..1200,300..900&amp;display=swap"> <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin> </head> <body> <p> &gt; <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon.png?157bbd74cef60250fd5a67a2e078966e"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://liuying-1.github.io/blog/2023/deconvolution/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js" integrity="sha256-rjmgmaB99riUNcdlrDtcAiwtLIojSxNyUFdl+Qh+rB4=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> <d-front-matter> <script async type="text/json">
      {
            "title": "Deconvolution",
            "description": "Image Restoration by Deconvolution",
            "published": "March 08, 2023",
            "authors": [
              
              {
                "author": "Ying Liu",
                "authorURL": "https://di.ku.dk/Ansatte/forskere/?pure=da/persons/762476",
                "affiliations": [
                  {
                    "name": "DIKU, UCPH",
                    "url": ""
                  }
                ]
              }
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> </p> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Y.</span> Liu </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">Ctrl K <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>Deconvolution</h1> <p>Image Restoration by Deconvolution</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div> <a href="#laplacian-image-sharpening">Laplacian image sharpening</a> </div> <ul> <li> <a href="#intuition">Intuition</a> </li> <li> <a href="#general-algorithm">General Algorithm</a> </li> <li> <a href="#implemented-using-a-laplacian-of-gaussian-filter-with-sigma-1">Implemented using a Laplacian of Gaussian filter with sigma = 1</a> </li> <li> <a href="#interpretation-scale-space">Interpretation - Scale Space</a> </li> <li> <a href="#laplacian-image-sharpening-and-noise">Laplacian image sharpening and noise</a> </li> </ul> <div> <a href="#deconvolution-the-fourier-transform-approach">Deconvolution - The Fourier transform approach</a> </div> <ul> <li> <a href="#image-degradation-model">Image degradation model</a> </li> <li> <a href="#linear-shift-invariant-lsi-degradation-model">Linear Shift Invariant (LSI) degradation model</a> </li> <li> <a href="#point-spread-function-psf">Point Spread Function (PSF)</a> </li> <li> <a href="#psf-s-from-real-imaging-system-can-be-complicated">PSF's from real imaging system can be complicated</a> </li> <li> <a href="#noise-sources">Noise sources</a> </li> <li> <a href="#examples-of-common-noise-distributions">Examples of common noise distributions</a> </li> <li> <a href="#example-of-image-enhancement-hubble-space-telescope">Example of image enhancement - Hubble space telescope</a> </li> <li> <a href="#direct-inverse-filtering">Direct Inverse Filtering</a> </li> <li> <a href="#deconvolution-in-the-presense-of-noise">Deconvolution in the presense of noise</a> </li> <li> <a href="#problems-with-noise">Problems with noise</a> </li> <li> <a href="#the-wiener-filter">The Wiener filter</a> </li> <li> <a href="#accounting-for-noise">Accounting for noise</a> </li> <li> <a href="#the-constant-approximation-is-usually-good">The constant approximation is usually good</a> </li> <li> <a href="#comparison">Comparison</a> </li> <li> <a href="#origin-of-the-wiener-filter">Origin of the Wiener filter</a> </li> <li> <a href="#alternative-view">Alternative view</a> </li> </ul> </nav> </d-contents> <div align="center"><img src="https://i.imgur.com/D4DTPMX.jpeg" alt="1531680863690_.pic" style="zoom:80%;" data-zoomable=""></div> <div class="reference" style="color: #999; font-size: 0.8em; margin-top: 1em; margin-bottom: 1em; ">Reference: Lecture from <a href="https://di.ku.dk/english/staff/vip/researchers_image/?pure=en/persons/83684" _target="blank" rel="external nofollow noopener" target="_blank">Kim Steenstrup Pedersen</a> </div> <h2 id="image-restoration-by-deconvolution">Image Restoration by Deconvolution</h2> <h3 id="laplacian-image-sharpening">Laplacian image sharpening</h3> <h4 id="intuition">Intuition</h4> <p>In Laplacian image sharpening, we use that the <strong><u>Laplacian filter ($2^{nd}$ order derivative) has high response values at either side of high constrast changes such as edges</u></strong>.</p> <div align="center"><img src="https://i.imgur.com/0CTe8El.png" alt="image-20230307133426430" style="zoom: 30%;" data-zoomable=""></div> <p>Here I have a step edge that I have smoothed by convolving with a gassuian of size sigma equals to 10. We just considered the 1D case, but it in general it is 2D.</p> <p>We have this blue image here, now, if we try to compute derivatives as we’ve done many times before, we can compute the first derivative and we do this using scale normalized derivative, so I’m multiply by the scale that I computed derivative at here I use the $tau = 10$.</p> <div align="center"><img src="https://i.imgur.com/2ep41DL.png" alt="image-20230307134805724" style="zoom: 30%;"></div> <div style="font-family:'noto serif sc'">拉普拉斯锐化图像是根据图像某个像素的周围像素到此像素的突变程度有关，也就是说它的依据是图像像素的变化程度。我们知道，一个函数的一阶微分描述了函数图像是朝哪里变化的，即增长或者降低；而二阶微分描述的则是图像变化的速度，急剧增长下降还是平缓的增长下降。那么据此我们可以猜测出依据二阶微分能够找到图像的色素的过渡程度，例如白色到黑色的过渡就是比较急剧的。或者用官方点的话说：当邻域中心像素灰度低于它所在的领域内其它像素的平均灰度时，此中心像素的灰度应被进一步降低，当邻域中心像素灰度高于它所在的邻域内其它像素的平均灰度时，此中心像素的灰度应被进一步提高，以此实现图像的锐化处理。应用：运用拉普拉斯可以增强图像的细节，找到图像的边缘。但是有时候会把噪音也给增强了，那么可以在锐化前对图像进行平滑处理。</div> <p>I could have chosen something different from the same value as the sigma but we will just use this. So we get the yellow line. If we want to do <strong>edge detection</strong>, we could look for <strong>local maximum of this first order derivative</strong>, but that is not we are interested here. =&gt; <em>First order derivative is used for edge detection</em></p> <p>If we consider the second derivative, scale normalized, in this case we have to multiply by $\tau^2$, then we get this green curve here.</p> <div align="center"><img src="https://i.imgur.com/5z9I0Rt.png" alt="image-20230307140219382" style="zoom: 30%;"></div> <p>Now the idea with Laplacian sharpening is basically that we take the second derivative for images, we consider the Laplacian operator which is the sum of two second derivatives and then, we take the original image in our case, the blue curve, and we subtract this laplacian image (second derivatives) from the blue curve.</p> <p>We can image that we take the blue curve subtract the green curve, we will be lowering this part because we have higher values of the laplacian in the left side. Similarly, in the right region, we could be rasing values of blue curve and in this way, we can manipulate the blue curve such that it becomes more sharp so the gradient of the curve gets steeper.</p> <div align="center"><img src="https://i.imgur.com/Vf0ZVrJ.png" alt="image-20230307141500386" style="zoom: 30%;"></div> <p>The red curve is now that I have taking the original image, the blue curve subtracted the scale normalized second derivative.</p> \[Red = Blue - Green \implies (Res = Original - Laplacian)\] <p>We can see that if we ignore this bump here, we can see the slope of the red curve is now larger than the blue curve, so we have achieved some form of sharpening.</p> <p>However, apparently also comes at a cost where we get some <strong>artifacts</strong> out here at this region (red outer parts) and similar down here where the edge starts and ends.</p> <div style="font-family:'noto serif sc'">观察蓝线和红线，红线作为我们的结果，确实它的梯度变强了因此得到了锐化，但是我们也付出了一些代价，因为红线部分有两个明显突出的假象。</div> <p>But this gragh is basically the intiituion of what this Laplacian image sharpening algorithm does.</p> <h4 id="general-algorithm">General Algorithm</h4> <p>To formulate it in more general for images, we have image $I$, and what we do is we compute the Laplacian response image $\sigma^2\nabla^2L(x, y: \sigma)$ with scale normalization.</p> <p>We need the mormalization because if we don’t do this, the green curve will be very low during the substraction, if we choose a high tau, which would mean that it doesn’t really have any effect. So we are in this situation where we actually need to be able to compare an image at two different scales. In this case, it’s the original scale of the blue curve which we know here by construction that it’s 10 and we compare that with the scale that we use to measure the illustration which in this case was tau = 10. And in order to do this in a fair manner, we need to normalize the derivatives.</p> <p><strong>Official Statement</strong></p> <p>In general, we can produce a sharpened version of the input image $I(x, y)$ by subtracting the Laplacian response image</p> \[J_{sharp}(x, y) = I(x, y) - \sigma^2\nabla^2L(x, y;\sigma)\] <p>with $L(x, y; \sigma) = (I * G)(x, y; \sigma)$ and $\nabla^2L = \partial^2L/\partial x^2 + \partial ^2 L/\partial y^2$.</p> <p>Note: We can use discrete Laplacian filters as described in G&amp;W or the scale normalized Laplacian of Gaussian filter.</p> <p>The note says we can leave out the scale normalization because then sigma would roughly be equal to 1 except if we use very large filters here.</p> <div style="font-family:'Noto Serif SC'">如果我们的filters不大，那么一般我们可以直接忽略归一化。默认为 sigma = 1。但是教授还是推荐用后者，归一化的拉普拉斯高斯算子。</div> <p>Let’s look at what happens when we apply this to an image.</p> <h4 id="implemented-using-a-laplacian-of-gaussian-filter-with-sigma--1">Implemented using a Laplacian of Gaussian filter with sigma = 1</h4> <div style="font-family:'noto serif sc'">高斯拉普拉斯算子又称为LOG(Laplacian of Gaussian)算子，是在高斯函数的基础上再利用拉普拉斯算子提取边缘得出的一个算子。 拉普拉斯算子是一种高通滤波器，是影像灰度函数在两个垂直方向二阶偏导数之和。</div> <p>Here I have a blurred image with a Gaussian filter with the sigma equal to 1, and we happen to know the good value for the scaled of the laplacian filter, so we set it equal to sigma = 1. Then, we apply the algorithm.</p> <div align="center"><img src="https://i.imgur.com/necjm6z.png" alt="image-20230307163012880" style="zoom:30%;"></div> <p>The third one is the resulting image of the Laplacian with scale normalized.</p> <p>So we take the original image do the subtraction with the third one, then, we get the sharpened image. =&gt; Second</p> <p>If looking carefully, the scarf and cheek actually look like the edges they are getting more crisp and sharp.</p> <h4 id="intepretation---scale-space">Intepretation - Scale Space</h4> <p>Pass</p> <h4 id="laplacian-image-sharpening-and-noise">Laplacian image sharpening and noise</h4> <p>It enhances noise.</p> <div align="center"><img src="https://i.imgur.com/gk1Fh58.png" alt="image-20230307164849915" style="zoom:30%;"></div> <p>Unfortunately, Laplacian image sharpening will have a tendency of boosting any noise that would be in the image.</p> <p>Here I took again the toy image blurred by gaussian of sigma equal to 1 <strong><u>and I also added some Gaussian noise</u></strong> to each of the pixels not much, but enough that you can visually see this. Then we can see that in the Laplacian image, the noise appears to be boosted. This also means that the sharpened version of the original image also becomes noisier.</p> <p>Basically, what happens is that, the noise accidentally gets enhanced. And we already know why this is.</p> <p>If you recall from a previous lecture where we discussed the differential filters and the sensitivity to noise. If we have a noisy signal, it doesn’t actually have to be that much noise. Then, its result gets amplified or enhanced by taking derivatives and this has to do with the thing that we in fact are subtracting two noisy pixels from each other which is the same thing as adding up noise.</p> <p>Unfortunately, when the differentiation order increases, this effect gets worse and worse. And now we are considering this a second-order derivative in Laplacian image sharpening. This means that it becomes more dominant than if we had done something that would involve the first derivative. =&gt; <font face="Noto Serif SC">拉普拉斯作为二阶比一阶受噪声影响更大。</font></p> <div align="center"><img src="https://i.imgur.com/Y5FBVUY.png" alt="image-20230307170507179" style="zoom: 25%;"></div> <h3 id="deconvolution---the-fourier-transform-approach">Deconvolution - The Fourier transform approach</h3> <p>In the rest of this lecture, we will consider the problem of image restoration by deconvolution and in fact, there are different approaches to solving this problem. But we will consider approaches that use the Fourier transformation as the way to define the algorithm.</p> <h4 id="image-degradation-model">Image degradation model</h4> <p><strong>What problem do we want to solve?</strong></p> <p>But first of all, we need to come up with a model of what we mean by degraded image.</p> <p>So, basically defined, what is the problem?</p> <hr> <p>In order to define algorithms for performing <strong>image restoration</strong>, we first need a model of the <strong>image degradation</strong> process.</p> <div align="center"><img src="https://i.imgur.com/Q3Fgrpu.png" alt="image-20230307180557604" style="zoom:50%;"></div> <p>So we will consider a system where we have some underlying clean image $f$ that gets degraded by mathematical operator or you can think of it as some system does something to the image.</p> <p>Then, on top of that, we allow for some noises to be added to the image.</p> <p>So what we are actually observing is $g$, a degraded image that is undergone some process here.</p> <div style="font-family:'noto serif sc'">现实中，造成图像退化的种类很多，常见的图像退化模型即点扩散函数（PSF）</div> <p><a href="https://blog.csdn.net/zssyu0416/article/details/80407870" rel="external nofollow noopener" target="_blank">Image Degradation</a></p> <p>To be more precise, the general model,</p> \[g(x, y) = h[f(x, y)] + n(x, y)\] <p>Where $h$ is a <strong>degradation operator</strong> and $n$ is an <strong>additive noise source</strong>.</p> <div style="font-family:'Noto Serif SC'">我的理解，这就是我们的成像过程：之前说的</div> \[I = PSF(F) + N\] <p><strong><em>The most important part here is that, I do not observe $f$ directly, I only observe $g$.</em></strong></p> <p>Our problem is then to come up with algorithms that can <strong>restore</strong> $f$ or at least approximate $f$ as close as possible.</p> <p><strong>Restoration</strong> produce $\hat f(x, y)$ and is an <strong>inverse problem</strong>. =&gt; The restoration procedure is to construct and some approximation $\hat f$ of the nice crisp and clean image here. It is an inverse problem as we only know the degraded image $g$.</p> <hr> <p>We have a model of the process that we believe that $g$ has undergone, and then we use this to try to define a solution that gives us a function that is as close as possible to $f$, the nice and crisp image.</p> <h4 id="linear-shift-invariant-lsi-degradation-model">Linear Shift Invariant (LSI) degradation model</h4> <p>If we assume that the degradation operator $h$ is position independent (shift invariant) and linear, we get the <strong>linear shift invariant degradation model</strong></p> \[g(x, y) = (h * f)(x, y) + n(x, y)\] <p>where $h(x, y)$ is the <strong>point spread function (PSF)</strong> of the degradation (imaging) system and as usual * denotes convolution.</p> <h4 id="point-spread-function-psf">Point Spread Function (PSF)</h4> <p>Recall from the first week lectures, what <strong>causes</strong> the PSF in an imaging system:</p> <div align="center"><img src="https://i.imgur.com/0zOy7GI.png" alt="image-20230307184236213" style="zoom: 30%;"></div> <p>One of the major causes are that the <strong>aperture</strong> and the <strong>sensor</strong> in the imaging system, they are <strong>finite</strong>. And this will cause <strong>blurring</strong> of the light that hits the actual CCD chip and the actual amount of light that I’ve recorded on the chip.</p> <p>On top of it, if we have a imperfect lens, then, it will cause some distortion in the light pattern which is referred to as lens distortion and this also contribute to this PSF function.</p> <p>Below is an example of a real system.</p> <h4 id="psfs-from-real-imaging-system-can-be-complicated">PSF’s from real imaging system can be complicated</h4> <div align="center"><img src="https://i.imgur.com/B7jMosD.png" alt="image-20230307185423636" style="zoom:25%;"></div> <p>So this comes from a microscope that has this PSF function. Let’s assume that we have this nice crisp objects here. And we now view this with microscope that has this PSF. That means we need to take this function and convolve with this image. And then we get a result like this.</p> <p>This example is just to illustrate that you can get some pretty crazy images out of a real imaging system, depending on the complexity of the PSF function. (Up to now, we’ve mainly just been looking at things like Gaussians and so on)</p> <h4 id="noise-sources">Noise sources</h4> <p>What about the noise? How do we actually model this?</p> <p>First of all, we made that choice of the noise being additive, you can also define this degradation model in terms of multiplicative noises, but it just involves a little bit more math.</p> <p>We can model the additive noise term $n(x, y)$ as a field of random variables - one for each pixel in the image.</p> <p>The random variable in each pixel is governed by a probability distribution and <u>we will often assume it is position independent</u> - in statistics the random variables are said to be <strong>independent and identically distributed (i.i.d.) or spatially uncorrelated.</strong> This type of noise is called white noise (and have a flat power spectrum =&gt; There is an equal amount of energy at all frequencies).</p> <p>If we sample from the noise source, e.g., draw random samples from the field of random variables, we get a noise image $n(x, y)$ which is called a <strong>realization of the noise source</strong>.</p> <p>Note: it is possible to imagine noise sources that are position dependent (i.e., not i.i.d.) and spatially correlated.</p> <div style="font-family:'Noto Serif SC'">这在我们的日常生活中也有可能发生，但是这其实只会让我们的模型变得有一点点难而已。</div> <p>The degradation model is the underlying theory that we need in order to define an algorithm to produce a restored image and remember the restored image is not exactly identical to the clean perfect crisp image, but is an approximation.</p> <h4 id="examples-of-common-noise-distributions">Examples of common noise distributions</h4> <p>Let’s just look at some concrete examples of noises, we’ve been using Gaussian Noise. But of course we can come up with other forms of noises here like Rayleigh distribution, Gamma distribution, Exponential Distribution, Uniform Distribution and Impulse distribution.</p> <div align="center"><img src="https://i.imgur.com/8z0LgiD.png" alt="image-20230307195831136" style="zoom: 40%;"></div> <p>Impulse distribution is basically what the salt and pepper does.</p> <div align="center"><img src="https://i.imgur.com/3qWGtTC.png" alt="image-20230307200047666" style="zoom: 33%;"></div> <p>If we try to apply this to a real simplified image with only three different grayscale values. We have added some Gaussian noise, Rayleigh noise, and Gamma noise. It might difficult to see when you look at these specific images here that there’s a difference in the noise sources, but once we do histograms of the intensities, we would clearly see there are different distributions in the noise here.</p> <h4 id="example-of-image-enhancement---hubble-space-telescope">Example of image enhancement - Hubble space telescope</h4> <p>This is a concrete example of a real image enhancement or restoration problem. This comes from the NASA Hubble Space Telescope. So originally when this Hubble space telescope launched, it was discovered that the telescopes Wide Field and Planetary Camera had a flawed mirror leading to blurred images.</p> <div align="center"><img src="https://i.imgur.com/18baoGi.png" alt="image-20230308084548752" style="zoom: 33%;"></div> <p>To correct this NASA estimated the <strong>PSF</strong> of the telescope and improved the images by <strong>deconvolution</strong> using the estimated PSF.</p> <p>Later the error was corrected by adding an extra mirror.</p> <div align="center"><img src="https://i.imgur.com/67V8gGm.png" alt="image-20230308084828337" style="zoom: 33%;"></div> <p>This is a star in the middle and an image taking of this star with this defect in the mirror. You could bascially see that this the sort of like a weird ringing pattern and that’s actually the PSF function that we’re seeing right there.We can think of stars as being point light sources in this setup here. So it would correspond to convolving with a PSF on images where you had a bunch of deltas spikes.</p> <p>The problem here is that you have several spikes or point light sources. But anyway, we can do things that try to estimate a function of PSF for this flawed mirror.</p> <div align="center"><img src="https://i.imgur.com/FGIwSDs.png" alt="image-20230308085616164" style="zoom: 33%;"></div> <p>The right one is actually not the result of deconvolution using this estimated PSF but the result of the improved mirror.</p> <p>But the idea is sort of the same, we would like to have an algorithm that could take an image like before, and generate that which looks nice one.</p> <h4 id="direct-inverse-filtering">Direct Inverse Filtering</h4> <p>So the image restoration process goes like this.</p> <p>We have this underlying degradation model which involves some clean version of the image $f$ that has been convolved by the system PSF, and some noise has been added and then, we observe this $g$. This is what we get out of our imaging system.</p> <p>Our problem is to come up with some filter that takes $g$ as its input.</p> <p>It should take $g$, the degraded image. It should take some estimated least of the system $h$, and some statistics of the noise, maybe even the probability distribution of the noise. Put these things together, what we would like is to solve this inverse problem of finding $f$ or rather at least get an estimated or approximation of $f$.</p> <div align="center"><img src="https://i.imgur.com/vZqB9Ez.png" alt="image-20230308101528791" style="zoom:33%;"></div> <p>This is the type of algorithms that we’re looking for some form of filter and is most likely a non-linear filter.</p> <p><strong><em>OK, let’s start with the simplest thing we can do in order to restore an image here.</em></strong></p> <p>This process here will be called <strong><em>deconvolution</em></strong> because it is similar to sort of inverting the process of convolution, and it is also called <strong><em>direct inverse filtering</em></strong>.</p> <p>The idea is that we start from the model, the LSI degradation model is</p> \[g(x, y) = (h*f)(x, y) + n(x, y)\] <p>Then we take the Fourier transform of the model, is (<strong>multiplication</strong>)</p> \[G(u, v) = H(u, v)F(u, v) + N(u, v)\] <p>So we have a convolution here in space, then, we know from the convolution theorem that the product in frequency domain. So it means that we need to take the Fourier transform of the $h$, and the Fourier transform of the clean image $f$. Similar to the noise, we just take the Fourier transofrm of an noise and add that =&gt; $N$.</p> <p>So this is the Fourier transform of the degraded image.</p> <hr> <p><strong><em>Note:</em></strong> <em>Just as what we have mentioned before, we could imagine a multiplicative noise model where instead of a plus but also a multiple application here. But that would make this Fourier Transform a little bit more involved because if you had a multipilication in space, that would translate into a convolution frequency which would mean that you would bascially have to take the term $H$ and convolve with the Fourier transform of the noise. =&gt; So becomes a little bit more involved.</em> We only consider the simple case here.</p> <hr> <p>If we also make it even simple and assume there is no noise, so,</p> <p>In the noise free case, $n(x, y) = 0$, deconvolution can be performed by the <strong>direct inverse filter</strong>.</p> <div align="center"><img src="https://i.imgur.com/lU4cpBu.png" alt="image-20230308104525667" style="zoom:25%;"></div> <p>If these several assumptions hold, this is actually the exact solution.</p> <p>Let me just add a little bit of extra thing.</p> <p>Assumes we know the Fourier transform of the PSF $H(u, v)$, also known as the Optical Transfer Function (OTF).</p> <p>Aso assumes that $H^{-1}(u, v)$ exists. In this case, the direct inverse filter provides an exact solution.</p> <div align="center"><img src="https://i.imgur.com/gCQOSAM.png" alt="image-20230308105027817" style="zoom:33%;"></div> <p>Any OTF where for some frequencies $(u, v), H(u, v) = 0$, is non-invertible (Division cannot be $0$). This problem can in some instances be handled by adding a small constant to $H(u, v)$ at all frequencies. Now the solution is only an approximation to the original (un-degraded) signal.</p> <p>So once we know the $H$ function, this is how we get an estimate of the Fourier transform of the clean image. So you just need to do the inverse Fourier transform, you get the clean image back.</p> <p>Let’s look at an example.</p> <p>Here we have a blurred image with Gaussian PSF $2^{nd}$. The corresponding OTF for $h$ is $3^{rd}$.</p> <div align="center"><img src="https://i.imgur.com/1j3I1qq.png" alt="image-20230308110035329" style="zoom:33%;"></div> <p>So, we take the degraded image, divided by the OTF, do the inverse Fourier transform of that result, and then, we get the clean image back.</p> <h4 id="deconvolution-in-the-presense-of-noise">Deconvolution in the presense of noise</h4> <p>But, what happens if we introduce noise?</p> <p>What happens in the noisy situation, $n(x, y)\neq 0$?</p> \[\hat {F} = F(u, v) + N(u, v)/ H(u, v)\] <p><strong>The noise is boosted</strong> by the direct inverse filter and will dominate the output solution.</p> <p>Example: If the noise have a flat constant power spectrum (white noise), then for all requencies where $H$ is small, $H « N$, the ratio will be large. These frequencies will dominate the output.</p> <div style="font-family:'Noto Serif SC'">观察第二项，如果我们在傅立叶域在某点有很小的H，这样就会导致噪声特别大。</div> <p>Example here a blurred image with some noise. And we can see the result is not so well by using direct inverse filtering approach.</p> <p>It could be like this is because our OTF here is close to zero for a lot of frequencies.</p> <h4 id="problems-with-noise">Problems with noise</h4> <div align="center"><img src="https://i.imgur.com/slL6gfJ.png" alt="image-20230308111042559" style="zoom:50%;"></div> <h4 id="the-wiener-filter">The Wiener filter</h4> <p>How to fix the problem of the direct inverse filter had <strong>in the presense of noise</strong>? =&gt; Wiener Filter</p> <p>The idea is to find another filter $\hat H$ that can be used to deconvolve the degraded image as close to the original image as possible, or $\hat F(u, v) = G(u, v)/\hat H(u, v)$.</p> <p>Solution to the least squares minimization problem</p> \[\min_{\hat f} E\{ (\hat f - f)^2 \}\] <p>where E is the expected value and $\hat f$ is recovered image and $f$ is the unknown clean image.</p> <p>The optimal LSI inverse filter in the least squares sense is called the <strong>Wiener filter</strong>.</p> <p>The solution has the inverse optical transfer function (OTF).</p> \[\frac{1}{H'(u, v)} = \frac{1}{H(u, v)} \frac{|H(u, v)^2|}{|H(u, v)|^2 + S_n(u, v)/S_f(u, v)}\] <p>Where</p> \[S_n(u, v) = |N(u, v)|^2, S_f(u, v) = |F(u, v)|^2\] <p>are the power spectra of the noise and the original image.</p> <p>Remember that</p> \[|X(u, v)|^2 = X(u, v)\bar{X}(u, v)\] <p>with $\bar{X}(u, v)$ denoting complex conjugation.</p> <h4 id="accounting-for-noise">Accounting for noise</h4> <p>The ratio $S_n(u, v)/ S_f(u, v)$, averaged over all frequencies $(u, v)$, is the inverse of the Signal-to-noise-ration (SNR).</p> <div style="font-family:'Noto Serif SC'">信噪比，how big is the noise relative to the actual signal.</div> <p>For white noise, the noise spectrum is a constant.</p> <p>The power spectrum of the un-degraded image is seldomly known, but we may approximate the ratio as a constant.</p> <p>The Wiener filter then reduces to</p> \[\frac{1}{H'(u, v)} = \frac{1}{H(u, v)}\frac{|H(u, v)|^2}{|H(u, v)|^2 + K}\] <p>Where $K$ is a scalar parameter.</p> <p>We only need to know the Fourier transform of the PSF, so we need to have an estimate of the PSF function of our imaging system.</p> <p>Below is the example of the Wiener Filter</p> <h4 id="the-constant-approximation-is-usually-good">The constant approximation is usually good</h4> <p>Let’s look at the effect of using this constant approximation.</p> <div align="center"><img src="https://i.imgur.com/qDpZaFW.png" alt="image-20230308121511649" style="zoom:50%;"></div> <p>Here we have a noisy blurred image, this is what happens when we use this constant approximation of the signal to noise ratio. The third one is the power spectrum of th enoise and the power spectrum of the clean image.</p> <p>You can see, if you compar these two deconvolved images, this image area is slightly more blurred than this. Of course, we don’t get rid of the noise, that’s not the purpose of the Wiener Filter. It’s just trying to remove the effect of the convolution that happened in the imaging process. (Remove the effect of the PSF).</p> <p>It might look slightly better when we actually know only all things so we can actually compute the correct signal to noise ratio. But the second one is already enough.</p> <p>So, in general, it’s the one in the middlt that you would use this as the third one does not really happen often in practice.</p> <h4 id="comparison">Comparison</h4> <p>Let’s compare direct inverse filtering and Wiener Filtering.</p> <div align="center"><img src="https://i.imgur.com/g4aaNXX.png" alt="image-20230308124329240" style="zoom:33%;"></div> <p>Assume that we have motion blur so that means that the PSF is all dragging or everythiing along some direction where we have motion. And we have added a little bit of noise.</p> <h4 id="origin-of-the-wiener-filter">Origin of the Wiener filter</h4> <p>The Wiener filter is the solution to a regularized least squares problem.</p> <p>And the problem looks like this, so it’s defined by a functional if you’re into machine learning, you can also think of this as a lost function where we want to minimize for $f$ that is the clean or at least an approximation of the clean image.</p> \[E[f] = ||f-g||^2 + \lambda||f||^2\] <p>We have this expression of that involved both $f$ and degraded image $g$.</p> <p>So, $f$ is what we want, and we don’t know it yet. But $g$ is given by observation.</p> <p>The expression means that we are comparing or taking differences squared differences between two function here or in the discrete case. The first item you can think of it to be the pixel-wise difference. And then, square this and take the sum overall pixels.</p> <p>The second term is the regularization term. We should take the pixel-wise squared and take the sum of all them.</p> <p>We are looking for the solution should be smooth and in this case the squared value should not be very large. The $\lambda$ allows us to control how much the smoothness term should dominate compared to this data term.</p> <p>We need to find $f$ to make the minimum of this expression.</p> <h4 id="alternative-view">Alternative view</h4> <p>There’s also an alternative view on which might also give a little bit of inside and that’s we can actually put a probabilistic interpretation of this. The Wiener filter is the maximum posteriori (MAP) estimate under the assumption of Gaussian noise and a Gaussian white noise prior distribution for unkonwn $f$ (a prior probability distribution on the space of images)</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/"></d-bibliography> <div id="giscus_thread" style="max-width: 930px; margin: 0 auto;"> <script>let giscusTheme=determineComputedTheme(),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"LiuYing-1/liuying-1.github.io","data-repo-id":"R_kgDOMScbNQ","data-category":"Announcements","data-category-id":"DIC_kwDOMScbNc4Cgruw","data-mapping":"pathname","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,e])=>giscusScript.setAttribute(t,e)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Y. Liu. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-JC70RZ57BT"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-JC70RZ57BT");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> </body> </html>